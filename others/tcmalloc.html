layout: false
---
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
               "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head><!-- <meta name="baidu-site-verification" content="707024a76f8f40b549f07f478abab237"/> -->
<title>tcmalloc</title>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
<meta name="title" content="tcmalloc"/>
<meta name="generator" content="Org-mode"/>
<meta name="generated" content="2014-01-02T19:55+0800"/>
<meta name="author" content="dirtysalt"/>
<meta name="description" content=""/>
<meta name="keywords" content=""/>
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  html { font-family: Times, serif; font-size: 12pt; }
  .title  { text-align: center; }
  .todo   { color: red; }
  .done   { color: green; }
  .tag    { background-color: #add8e6; font-weight:normal }
  .target { }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  {margin-left:auto; margin-right:0px;  text-align:right;}
  .left   {margin-left:0px;  margin-right:auto; text-align:left;}
  .center {margin-left:auto; margin-right:auto; text-align:center;}
  p.verse { margin-left: 3% }
  pre {
	border: 1pt solid #AEBDCC;
	background-color: #F3F5F7;
	padding: 5pt;
	font-family: courier, monospace;
        font-size: 90%;
        overflow:auto;
  }
  table { border-collapse: collapse; }
  td, th { vertical-align: top;  }
  th.right  { text-align:center;  }
  th.left   { text-align:center;   }
  th.center { text-align:center; }
  td.right  { text-align:right;  }
  td.left   { text-align:left;   }
  td.center { text-align:center; }
  dt { font-weight: bold; }
  div.figure { padding: 0.5em; }
  div.figure p { text-align: center; }
  div.inlinetask {
    padding:10px;
    border:2px solid gray;
    margin:10px;
    background: #ffffcc;
  }
  textarea { overflow-x: auto; }
  .linenr { font-size:smaller }
  .code-highlighted {background-color:#ffff00;}
  .org-info-js_info-navigation { border-style:none; }
  #org-info-js_console-label { font-size:10px; font-weight:bold;
                               white-space:nowrap; }
  .org-info-js_search-highlight {background-color:#ffff00; color:#000000;
                                 font-weight:bold; }
  /*]]>*/-->
</style><link rel="shortcut icon" href="http://blog.com/css/favicon.ico" /> <link rel="stylesheet" type="text/css" href="./css/site.css" />


</head>
<body><!-- <div id="bdshare" class="bdshare_t bds_tools_32 get-codes-bdshare"><a class="bds_tsina"></a><span class="bds_more"></span><a class="shareCount"></a></div> --><!-- Place this tag where you want the +1 button to render --><!-- <g:plusone annotation="inline"></g:plusone> -->

<div id="preamble">

</div>

<div id="content">
<h1 class="title">tcmalloc</h1>


<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1 tcmalloc</a>
<ul>
<li><a href="#sec-1-1">1.1 函数入口</a></li>
<li><a href="#sec-1-2">1.2 全局内存</a></li>
<li><a href="#sec-1-3">1.3 管理对象</a>
<ul>
<li><a href="#sec-1-3-1">1.3.1 TCMallocGuard</a></li>
<li><a href="#sec-1-3-2">1.3.2 PageHeapAllocator</a></li>
<li><a href="#sec-1-3-3">1.3.3 SizeMap</a></li>
<li><a href="#sec-1-3-4">1.3.4 Central Cache</a>
<ul>
<li><a href="#sec-1-3-4-1">1.3.4.1 Data Structure</a></li>
<li><a href="#sec-1-3-4-2">1.3.4.2 Init</a></li>
<li><a href="#sec-1-3-4-3">1.3.4.3 InsertRange</a></li>
<li><a href="#sec-1-3-4-4">1.3.4.4 RemoveRange</a></li>
<li><a href="#sec-1-3-4-5">1.3.4.5 Populate</a></li>
</ul>
</li>
<li><a href="#sec-1-3-5">1.3.5 PageHeap</a>
<ul>
<li><a href="#sec-1-3-5-1">1.3.5.1 Data Structure</a></li>
<li><a href="#sec-1-3-5-2">1.3.5.2 New</a></li>
<li><a href="#sec-1-3-5-3">1.3.5.3 Carve</a></li>
<li><a href="#sec-1-3-5-4">1.3.5.4 GrowHeap</a></li>
<li><a href="#sec-1-3-5-5">1.3.5.5 Delete</a></li>
<li><a href="#sec-1-3-5-6">1.3.5.6 IncrementalScavenge</a></li>
<li><a href="#sec-1-3-5-7">1.3.5.7 ReleaseAtLeastNPages</a></li>
<li><a href="#sec-1-3-5-8">1.3.5.8 Split</a></li>
<li><a href="#sec-1-3-5-9">1.3.5.9 GetNextRange</a></li>
</ul>
</li>
<li><a href="#sec-1-3-6">1.3.6 TCMalloc_PageMap3</a></li>
<li><a href="#sec-1-3-7">1.3.7 PackedCache</a></li>
<li><a href="#sec-1-3-8">1.3.8 Thread Cache</a>
<ul>
<li><a href="#sec-1-3-8-1">1.3.8.1 Data Structure</a></li>
<li><a href="#sec-1-3-8-2">1.3.8.2 InitModule</a></li>
<li><a href="#sec-1-3-8-3">1.3.8.3 InitTSD</a></li>
<li><a href="#sec-1-3-8-4">1.3.8.4 GetCache</a></li>
<li><a href="#sec-1-3-8-5">1.3.8.5 CreateCacheIfNecessary</a></li>
<li><a href="#sec-1-3-8-6">1.3.8.6 NewHeap</a></li>
<li><a href="#sec-1-3-8-7">1.3.8.7 BecomeIdle</a></li>
<li><a href="#sec-1-3-8-8">1.3.8.8 Init</a></li>
<li><a href="#sec-1-3-8-9">1.3.8.9 ThreadCache::FreeList</a></li>
<li><a href="#sec-1-3-8-10">1.3.8.10 IncreaseCacheLimitLocked</a></li>
<li><a href="#sec-1-3-8-11">1.3.8.11 DeleteCache</a></li>
<li><a href="#sec-1-3-8-12">1.3.8.12 Cleanup</a></li>
<li><a href="#sec-1-3-8-13">1.3.8.13 ReleaseToCentralCache</a></li>
<li><a href="#sec-1-3-8-14">1.3.8.14 Allocate</a></li>
<li><a href="#sec-1-3-8-15">1.3.8.15 FetchFromCentralCache</a></li>
<li><a href="#sec-1-3-8-16">1.3.8.16 Deallocate</a></li>
<li><a href="#sec-1-3-8-17">1.3.8.17 ListTooLong</a></li>
<li><a href="#sec-1-3-8-18">1.3.8.18 Scavenge</a></li>
</ul></li>
</ul>
</li>
<li><a href="#sec-1-4">1.4 用户对象</a>
<ul>
<li><a href="#sec-1-4-1">1.4.1 函数入口</a></li>
<li><a href="#sec-1-4-2">1.4.2 分配逻辑</a></li>
<li><a href="#sec-1-4-3">1.4.3 释放逻辑</a></li>
</ul>
</li>
<li><a href="#sec-1-5">1.5 扩展组件</a>
<ul>
<li><a href="#sec-1-5-1">1.5.1 Sampler</a></li>
<li><a href="#sec-1-5-2">1.5.2 MallocExtension</a></li>
<li><a href="#sec-1-5-3">1.5.3 MallocHook</a></li>
<li><a href="#sec-1-5-4">1.5.4 HeapChecker</a></li>
<li><a href="#sec-1-5-5">1.5.5 HeapProfiler</a></li>
<li><a href="#sec-1-5-6">1.5.6 CPUProfiler</a></li>
</ul>
</li>
<li><a href="#sec-1-6">1.6 Discussion</a>
<ul>
<li><a href="#sec-1-6-1">1.6.1 tcmalloc中的 MmapSysAllocator::Alloc 疑问(nwlzee)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> tcmalloc</h2>
<div class="outline-text-2" id="text-1">


<ul>
<li>内存管理内幕 <a href="http://www.ibm.com/developerworks/cn/linux/l-memory/">http://www.ibm.com/developerworks/cn/linux/l-memory/</a>
</li>
<li>hoard内存分配器 <a href="http://www.hoard.org/">http://www.hoard.org/</a>
</li>
<li>dlmalloc内存分配器 <a href="http://gee.cs.oswego.edu/dl/html/malloc.html">http://gee.cs.oswego.edu/dl/html/malloc.html</a>
</li>
<li>ptmalloc2内存分配器 <a href="http://www.malloc.de/en/index.html">http://www.malloc.de/en/index.html</a>
</li>
<li>jemalloc内存分配器 <a href="http://people.freebsd.org/~jasone/jemalloc/bsdcan2006/jemalloc.pdf">http://people.freebsd.org/%7Ejasone/jemalloc/bsdcan2006/jemalloc.pdf</a>
</li>
<li>jemalloc地址 <a href="http://www.canonware.com/download/jemalloc/">http://www.canonware.com/download/jemalloc/</a>
</li>
<li>tcmalloc内存分配器 <a href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html">http://goog-perftools.sourceforge.net/doc/tcmalloc.html</a>
</li>
<li>tcmalloc地址 <a href="http://google-perftools.googlecode.com/files/google-perftools-1.8.3.tar.gz">http://google-perftools.googlecode.com/files/google-perftools-1.8.3.tar.gz</a>
</li>
</ul>


<p>
<b>如果你对使用tcmalloc有什么问题的话，请给我发邮件。我会尽量给你答复，对于常见的问题也会整理到FAQ上面。</b>
</p>
<p>
jemalloc论文上面谈到了很多关于内存分配器方面的基本概念与问题。
性能指标主要体现在分配时间以及平均和高峰内存使用大小上面。但是两个指标很难单独测量，所以现在比较权威的测量方式还是使用benchmark然后看看运行时间以及内存使用量。内存碎片分为内部碎片和外部碎片。
内部碎片通常都是因为分配的话会进行round之后而没有使用的部分，而外部碎片指已经回收但是因为地址不连续等原因没有办法被应用程序使用的部分。
jemalloc提高CPU Cache命中率有两个途径：
</p><ul>
<li>首先尽可能地让内存使用更小。working set可以放在cache-line里面全部存放效率就会比较好。
</li>
<li>另外就是应该让连续开辟的对象放在一起。jemalloc是假设在一个线程内部调用两次的malloc的话，那么通常是在一起访问的。
</li>
</ul>

<p>第一个假设非常合理，但是第二个假设不一定是合理的。jemalloc首先确保第一个前提，然后尽可能地保证第二个条件。
另外cache命中率的一个问题就是false-cache-line.简单的说就是两个线程开辟的对象(A,B)可能连在一起，可以一起载入cache-line.线程1对于A的修改会造成线程2下一次读取B的时候，需要重新从内存载入，因为对于A的修改会使得所在的cache-line失效。解决这个问题的办法就是有多个allocation arena.不同的线程尽可能在不同的arena下面开辟。
</p>
<p>
锁冲突是造成传统malloc在多线程情况下表现差的主要原因。解决的方法和解决false-cache-line是一样的，都是开辟多个allocation arena然后让不同的线程尽可能地在不同的arena分配。
</p>
<p>
ptmalloc2解决为了解决锁冲突这个问题，也采用了arena-per-thread的方法。但是ptmalloc2内部依然存在一个大的问题，就是各个arena之间是没有办法迁移的。
如果一个线程一开始开辟很大但是之后释放了，那个这块内存是没有办法被其他线程所使用的。
</p>
<p>
同样tcmalloc会为每一个线程分配一个arena,这样每一个线程分配时候都不需要进行加锁。但是tcmalloc解决了ptmalloc2的内存迁移问题。
tcmalloc如果发现thread cache内部占用率高但是使用率低的话，那么会将部分内存存放在中心部分。基本上jemalloc原理上和tcmalloc相似。
每个线程有一个arena池，但是线程按照round-robin方式在每一个arena上面取。代价是需要加锁，但是假设冲突应该不严重。
</p>
<p>
后面我们着重针对tcmalloc进行分析。tcmalloc文档写的足够好了，看完一遍基本上就知道内部原理了。所以这里我也只是自己总结一下，然后用自己的理解写出来。里面尽量附上代码分析:)
tcmalloc代码写得相当得好，虽然很多地方没有看懂(而且我猜想有很多地方已经过时了但是没有删去，所以对于代码阅读有一定的影响).基本上阅读完tcmalloc阅读和编写代码能力会提高很多。
看下面分析之前，还是强烈建议先阅读一次文档。
</p>

</div>

<div id="outline-container-1-1" class="outline-3">
<h3 id="sec-1-1"><span class="section-number-3">1.1</span> 函数入口</h3>
<div class="outline-text-3" id="text-1-1">

<p>tcmalloc.cc
</p>
<p>
tcmallo.cc里面定义了函数入口.对于安排在section(google_malloc)不知道有作用。当然下面有很多相关的函数比如tc_memalign，但是这些并不影响阅读主线。
我们只需要关心两个函数tc_malloc以及tc_free即可。
</p>


<pre class="src src-C++">#include &lt;malloc.h&gt;
#define __THROW
# define ATTRIBUTE_SECTION(name) __attribute__ ((section (#name)))
extern <span class="org-string">"C"</span> {
  void* tc_malloc(size_t size) __THROW
      ATTRIBUTE_SECTION(google_malloc);
  void tc_free(void* ptr) __THROW
      ATTRIBUTE_SECTION(google_malloc);
}
</pre>


<p>
然后在libc_override_gcc_and_weak.h和libc_override_glibc.h进行了函数替换
</p>


<pre class="src src-C++">#define ALIAS(tc_fn)   __attribute__ ((alias (#tc_fn)))
extern <span class="org-string">"C"</span> {
  void* __libc_malloc(size_t size)                ALIAS(tc_malloc);
  void __libc_free(void* ptr)                     ALIAS(tc_free);
} // extern <span class="org-string">"C"</span>
extern <span class="org-string">"C"</span> {
  void* malloc(size_t size) __THROW               ALIAS(tc_malloc);
  void free(void* ptr) __THROW                    ALIAS(tc_free);
} // extern <span class="org-string">"C"</span>
</pre>


<p>
同时在里面还覆盖了malloc_hook和free_hook这两个函数，不允许用户自己进行hook.
我猜想tcmalloc应该是自己提供了malloc_hook和free_hook的定义.
</p>


<pre class="src src-C++">extern <span class="org-string">"C"</span> {
static void* glibc_override_malloc(size_t size, const void *caller) {
  return tc_malloc(size);
}
static void glibc_override_free(void *ptr, const void *caller) {
  tc_free(ptr);
}
void* (* MALLOC_HOOK_MAYBE_VOLATILE __malloc_hook)(size_t, const void*)
    = &amp;glibc_override_malloc;
void (* MALLOC_HOOK_MAYBE_VOLATILE __free_hook)(void*, const void*)
    = &amp;glibc_override_free;
} // extern <span class="org-string">"C"</span>
</pre>


<p>
仔细阅读tcmalloc.cc接口面还发现了下面这些接口非常有意思
</p>


<pre class="src src-C++">// &#36820;&#22238;&#24403;&#21069;malloc&#20449;&#24687;,&#22312;malloc.h&#37324;&#38754;&#26377;&#23450;&#20041;
struct mallinfo tc_mallinfo(void) __THROW ATTRIBUTE_SECTION(google_malloc);
// &#36825;&#20010;&#25351;&#38024;&#23454;&#38469;&#21487;&#29992;&#20869;&#23384;&#22823;&#23567;
size_t tc_malloc_size(void* p) __THROW ATTRIBUTE_SECTION(google_malloc);
// &#25171;&#21360;&#24403;&#21069;malloc&#29366;&#24577;
void tc_malloc_stats(void) __THROW  ATTRIBUTE_SECTION(google_malloc);
// &#20462;&#25913;malloc&#21442;&#25968;,&#22312;malloc.h&#37324;&#38754;&#26377;&#20462;&#25913;&#36873;&#39033;
int tc_mallopt(int cmd, int value) __THROW ATTRIBUTE_SECTION(google_malloc);
</pre>

<p>
可以结合当前的ptmalloc2(glibc.2.3.4)来看看这些接口的行为.了解这些行为主要是对于内存分配器如果出问题的话，那么至少有方法可以了解内部情况.
</p>
</div>

</div>

<div id="outline-container-1-2" class="outline-3">
<h3 id="sec-1-2"><span class="section-number-3">1.2</span> 全局内存</h3>
<div class="outline-text-3" id="text-1-2">

<p>system-alloc.h
</p>



<pre class="src src-C++">extern void* TCMalloc_SystemAlloc(size_t bytes, size_t *actual_bytes,
                                  size_t alignment = 0);
extern void TCMalloc_SystemRelease(void* start, size_t length);
</pre>

<p>
基本可以认为Release部分没有任何操作。对于SystemAlloc底层实现非常巧妙.首先tcmalloc定义了SysAllocator这个接口，然后底层有两个实现：
</p><ul>
<li>SbrkSysAllocator.使用sbrk来分配内存
</li>
<li>MmapSysAllocator.使用mmap来分配内存
</li>
</ul>

<p>SysAllocator需要实现一个接口void* Alloc(size_t size, size_t *actual_size, size_t alignment);因为全局只是需要一个这样的对象，
所以这个对象可以静态分配即可.然后定义了一个DefaultSysAllocator允许设置Children.
</p>


<pre class="src src-C++">static char sbrk_space[sizeof(SbrkSysAllocator)];
static char mmap_space[sizeof(MmapSysAllocator)];
static char default_space[sizeof(DefaultSysAllocator)];
</pre>


<p>
在初始化InitSystemAllocators的时候将sbrk_space以及mmap_space作为default_space的两个children.
</p>


<pre class="src src-C++">MmapSysAllocator *mmap = new (mmap_space) MmapSysAllocator();
SbrkSysAllocator *sbrk = new (sbrk_space) SbrkSysAllocator();
DefaultSysAllocator *sdef = new (default_space) DefaultSysAllocator();
if (kDebugMode &amp;&amp; sizeof(void*) &gt; 4) {
  sdef-&gt;SetChildAllocator(mmap, 0, mmap_name);
  sdef-&gt;SetChildAllocator(sbrk, 1, sbrk_name);
} else {
  sdef-&gt;SetChildAllocator(sbrk, 0, sbrk_name);
  sdef-&gt;SetChildAllocator(mmap, 1, mmap_name);
}
</pre>

<p>
实际操作时候都是先sbrk尝试先，然后使用mmap.DefaultAllocator按照children顺序尝试分配，也就意味着首先使用sbrk如果不成功尝试mmap
</p>


<pre class="src src-C++">void* DefaultSysAllocator::Alloc(size_t size, size_t *actual_size,
                                 size_t alignment) {
  for (int i = 0; i &lt; kMaxAllocators; i++) {
    if (!failed_[i] &amp;&amp; allocs_[i] != NULL) {
      void* result = allocs_[i]-&gt;Alloc(size, actual_size, alignment);
      if (result != NULL) {
        return result;
      }
      TCMalloc_MESSAGE(__FILE__, __LINE__, <span class="org-string">"%s failed.\n"</span>, names_[i]);
      failed_[i] = true;
    }
  }
  // After both failed, reset <span class="org-string">"failed_"</span> to false so that a single failed
  // allocation won't make the allocator never work again.
  for (int i = 0; i &lt; kMaxAllocators; i++) {
    failed_[i] = false;
  }
  return NULL;
}
</pre>

<p>
可以说系统里面所有使用的内存都是从这个地方分配的，包括thread_cache,page_allocator以及管理对象。
此外还需要注意的是，因为会有多线程调用这个东西，所以在SystemAlloc之前的话会调用自选锁进行锁定。SpinLockHolder lock_holder(&amp;spinlock);
</p>
</div>

</div>

<div id="outline-container-1-3" class="outline-3">
<h3 id="sec-1-3"><span class="section-number-3">1.3</span> 管理对象</h3>
<div class="outline-text-3" id="text-1-3">

<ul>
<li>tcmalloc_guard.h
</li>
<li>static_vars.h
</li>
<li>page_heap_allocator.h
</li>
<li>common.h
</li>
<li>central_freelist.h
</li>
<li>page_heap.h
</li>
<li>page_map.h
</li>
<li>packed-cache-inl.h
</li>
<li>thread_cache.h
</li>
</ul>



</div>

<div id="outline-container-1-3-1" class="outline-4">
<h4 id="sec-1-3-1"><span class="section-number-4">1.3.1</span> TCMallocGuard</h4>
<div class="outline-text-4" id="text-1-3-1">

<p>tcmalloc_guard.h
</p>
<p>
TCMallocGuard主要是为了确保在tc_malloc之前所有静态变量都已经完成了初始化。首先全局存在一个static TCMallocGuard module_enter_exit_hook;
这个变量来确保静态初始化，但是同时为了防止重复初始化还加了引用计数进行判断
</p>


<pre class="src src-C++">static int tcmallocguard_refcount = 0;  // no lock needed: runs before main()
TCMallocGuard::TCMallocGuard() {
  if (tcmallocguard_refcount++ == 0) {
    ReplaceSystemAlloc();    // defined in libc_override_*.h // &#36825;&#20010;&#23545;&#20110;Linux&#26469;&#35828;&#27809;&#26377;&#20219;&#20309;&#25805;&#20316;
    tc_free(tc_malloc(1)); // &#36825;&#20010;&#22320;&#26041;&#20010;&#20154;&#35273;&#24471;&#27809;&#26377;&#24517;&#35201;&#65292;&#21487;&#33021;&#21482;&#26159;&#20026;&#20102;&#30475;&#30475;&#26159;&#21542;&#21487;&#20197;&#20877;InitTSD&#20043;&#21069;run&#36215;&#26469;
    ThreadCache::InitTSD(); // &#21021;&#22987;&#21270;&#19968;&#19979;tc&#30340;&#32447;&#31243;&#23616;&#37096;&#21464;&#37327;
    tc_free(tc_malloc(1));
    if (RunningOnValgrind()) { // &#20174;&#20195;&#30721;&#19978;&#30475;&#21487;&#33021;&#26159;&#20174;&#29615;&#22659;&#21464;&#37327;&#37324;&#38754;&#33719;&#21462;&#30340;&#12290;
      // Let Valgrind uses its own malloc (so don't register our extension).
    } else { // TODO.???&#23545;&#20110;MallocExtension&#20197;&#21450;MallocHook&#36824;&#19981;&#26159;&#24456;&#20102;&#35299;
      MallocExtension::Register(new TCMallocImplementation);
    }
  }
}
</pre>


<p>
对于释放来说的话也非常简单，可以根据环境变量来选择是否打印统计信息
</p>


<pre class="src src-C++">TCMallocGuard::~TCMallocGuard() {
  if (--tcmallocguard_refcount == 0) {
    const char* env = getenv(<span class="org-string">"MALLOCSTATS"</span>);
    if (env != NULL) {
      int level = atoi(env);
      if (level &lt; 1) level = 1;
      PrintStats(level);
    }
  }
}
</pre>


</div>

</div>

<div id="outline-container-1-3-2" class="outline-4">
<h4 id="sec-1-3-2"><span class="section-number-4">1.3.2</span> PageHeapAllocator</h4>
<div class="outline-text-4" id="text-1-3-2">

<p>page_heap_allocator.h
</p>
<p>
如果管理对象预先知道了大小那么可以静态分配使用in-placement new方式完成，但是如果管理对象是动态分配的话，那么如何管理这些对象的分配呢？
答案非常简单使用sample_alloc.所以sample_alloc就是这个分配器知道了每次分配对象的大小，回收缓存起来挂在free_list上面，分配首先从free_list尝试分配，
如果free_list为空的话，那么久会调用全局内存分配。
</p>
<p>
page_heap_allocator.h里面实现了一个sample_alloc叫做PageHeapAllocator.原理来说非常简单，这里就不赘述了。需要注意的是每一个节点肯定都是&gt;sizeof(void*)的，
所以每个节点不用分配额外的next指针空间，这个是一个基本上所以写过内存分配器程序员公开的技巧了。另外需要关注的是每次向全局内存空间要的大小是多少
</p>


<pre class="src src-C++">static const int kAllocIncrement = 128 &lt;&lt; 10; // 128K
</pre>

<p>
里面还维护了一个inuse()接口表示当前有多少个object正在被使用。
</p>
<p>
另外为了更好的统计管理对象使用的内存，在common.cc里面记录了元信息分配的内存大小
</p>


<pre class="src src-C++">static uint64_t metadata_system_bytes_ = 0;
void* MetaDataAlloc(size_t bytes) {
  void* result = TCMalloc_SystemAlloc(bytes, NULL);
  if (result != NULL) {
    metadata_system_bytes_ += bytes;
  }
  return result;
}
uint64_t metadata_system_bytes() { return metadata_system_bytes_; }
</pre>

<p>
只要所有的元信息都从MetaDataAlloc这里分配即可。
</p>
</div>

</div>

<div id="outline-container-1-3-3" class="outline-4">
<h4 id="sec-1-3-3"><span class="section-number-4">1.3.3</span> SizeMap</h4>
<div class="outline-text-4" id="text-1-3-3">

<p>common.h
</p>
<p>
SizeMap定义了slab大小，大小到slab编号的映射，一种slab每次分配的多少个pages，一种slab的话在tc和central cache中每次移动多少个对象。
具体定义可以阅读common.h.里面的算法个人觉得还是比较复杂的没有仔细研究。slab的一共有
</p>


<pre class="src src-C++">#if defined(TCMALLOC_LARGE_PAGES)
static const size_t kPageShift  = 15;
static const size_t kNumClasses = 78;
#else
static const size_t kPageShift  = 13;
static const size_t kNumClasses = 86;
#endif
</pre>

<p>
对于我们如果使用大页面的话，32K的话那么有77种slab,否则只有85种。注意这里slab的编号从1开始计算。
</p>
<p>
tcmalloc提供了一个Dump方法可以查看最终这些数值。我们需要和源代码联合编译才有可能看到
</p>


<pre class="src src-C++">#include &lt;cstdio&gt;
#include &lt;src/internal_logging.h&gt;
#include &lt;src/static_vars.h&gt;

char buf[1024*1024];
int main() {
  // initialize tcmalloc
  void* p=malloc(10);
  free(p);
  tcmalloc::SizeMap* sizemap=tcmalloc::Static::sizemap();
  // print aux info
  for(int i=1;i&lt;kNumClasses;i++){
    printf(<span class="org-string">"SC %d [%d]\n"</span>,i,sizemap-&gt;num_objects_to_move(i));
  }
  // print stats.
  TCMalloc_Printer printer(buf,sizeof(buf));
  sizemap-&gt;Dump(&amp;printer);
  printf(<span class="org-string">"%s\n"</span>,buf);
  return 0;
}
</pre>


<p>
查看结果是
</p>


<pre class="example">SC 1 [32]
SC 2 [32]
SC 3 [32]
SC 4 [32]
SC 5 [32]
SC 6 [32]
SC 7 [32]
SC 8 [32]
SC 9 [32]
...

SC   1 [        1 ..        8 ] from     8192 ; 88% maxwaste
SC   2 [        9 ..       16 ] from     8192 ; 44% maxwaste
SC   3 [       17 ..       32 ] from     8192 ; 47% maxwaste
SC   4 [       33 ..       48 ] from     8192 ; 32% maxwaste
SC   5 [       49 ..       64 ] from     8192 ; 23% maxwaste
SC   6 [       65 ..       80 ] from     8192 ; 19% maxwaste
SC   7 [       81 ..       96 ] from     8192 ; 16% maxwaste
....
</pre>

<p>
这个意思就很清楚，对于slab1的对象来说的话，每次会将32个对象在tc(thread cache)和cc(central cache)之间调动。
如果是1-8字节的话那么按照8字节分配，如果分配pages的话那分配8192字节。最大浪费率是88%(8-1)/8.
对于81-96字节的话，那么最大浪费率就是(96-81)/96-16%.
(注意这里打印分配pages的话已经&lt;&lt; kPageShift,如果kPageShift=12的话，8192字节那么相当于2pages)
</p>
</div>

</div>

<div id="outline-container-1-3-4" class="outline-4">
<h4 id="sec-1-3-4"><span class="section-number-4">1.3.4</span> Central Cache</h4>
<div class="outline-text-4" id="text-1-3-4">

<p>central_freelist.h
</p>

</div>

<div id="outline-container-1-3-4-1" class="outline-5">
<h5 id="sec-1-3-4-1"><span class="section-number-5">1.3.4.1</span> Data Structure</h5>
<div class="outline-text-5" id="text-1-3-4-1">

<p>首先在static里面定义的central_cache是一个数组大小为kNumClasses，相当于和每一个thread cache里面的slab对应。
数组每个元素是CentralFreeListPadded,在central_freelist.h里面定义的。阅读CentralFreeListPadded这个结构，就会发现，
实际上这个功能是在CentralFreeList里面的，为了能够进行align进行了padded,还是非常巧妙的
</p>


<pre class="src src-C++">template&lt;int kFreeListSizeMod64&gt;
class CentralFreeListPaddedTo : public CentralFreeList {
 private:
  char pad_[64 - kFreeListSizeMod64];
};

template&lt;&gt;
class CentralFreeListPaddedTo&lt;0&gt; : public CentralFreeList {
};

class CentralFreeListPadded : public CentralFreeListPaddedTo&lt;
  sizeof(CentralFreeList) % 64&gt; {
};
</pre>

<p>
所以后续的话我们只需要关注CentralFreeList即可。
</p>
<p>
数据结构基本上还是很好理解的:).
</p>


<pre class="src src-C++">class CentralFreeList {
 private:
  // TransferCache is used to cache transfers of
  // sizemap.num_objects_to_move(size_class) back and forth between
  // thread caches and the central cache for a given size class.
  struct TCEntry {
    void *head;  // Head of chain of objects.
    void *tail;  // Tail of chain of objects.
  };
  // A central cache freelist can have anywhere from 0 to kMaxNumTransferEntries
  // slots to put link list chains into.
#ifdef TCMALLOC_SMALL_BUT_SLOW
  // For the small memory model, the transfer cache is not used.
  static const int kMaxNumTransferEntries = 0;
#else
  // Starting point for the the maximum number of entries in the transfer cache.
  // This actual maximum for a given size class may be lower than this
  // maximum value.
  static const int kMaxNumTransferEntries = 64;
#endif
  // This lock protects all the data members.  cached_entries and cache_size_
  // may be looked at without holding the lock.
  SpinLock lock_;

  // We keep linked lists of empty and non-empty spans.
  size_t   size_class_;     // My size class
  Span     empty_;          // Dummy header for list of empty spans
  Span     nonempty_;       // Dummy header for list of non-empty spans
  size_t   num_spans_;      // Number of spans in empty_ plus nonempty_
  size_t   counter_;        // Number of free objects in cache entry

  // Here we reserve space for TCEntry cache slots.  Space is preallocated
  // for the largest possible number of entries than any one size class may
  // accumulate.  Not all size classes are allowed to accumulate
  // kMaxNumTransferEntries, so there is some wasted space for those size
  // classes.
  TCEntry tc_slots_[kMaxNumTransferEntries];

  // Number of currently used cached entries in tc_slots_.  This variable is
  // updated under a lock but can be read without one.
  int32_t used_slots_;  // &#24403;&#21069;&#20351;&#29992;&#30340;tc entries.
  // The current number of slots for this size class.  This is an
  // adaptive value that is increased if there is lots of traffic
  // on a given size class.
  int32_t cache_size_; // &#24403;&#21069;&#20801;&#35768;&#30340;&#26368;&#22823;&#30340;tc entries.
  // Maximum size of the cache for a given size class.
  int32_t max_cache_size_; // &#26368;&#22823;&#20801;&#35768;&#22810;&#23569;&#20010;tc entries.
}
</pre>


<p>
CentralFreeList的接口非常少
</p><ul>
<li>void Init(size_t cl); // 初始化,cl表示自己是第几个class
</li>
<li>void InsertRange(void *start, void *end, int N); // 回收部分objects.
</li>
<li>int RemoveRange(void **start, void **end, int N); // 分配部分objects.
</li>
<li>length // 在cache里面存在多少个free objects(不包含transfer cache)
</li>
<li>tc_length // transfer cache里面包含多少free objects.
</li>
<li>OverheadBytes // 因为内部碎片造成的额外开销
</li>
</ul>

<p>因为cc是被全局操作的，所以这些接口在实际操作的时候内部都会首先尝试加上自选锁。很明显cc里面使用了free list链表结构管理这些free object.
之前说过ptmalloc2会有这么一个问题，就是如果局部线程分配过多的话没有机制将内存返回给主区域。而tcmalloc解决了这个问题。
对于每一个slab的tc返回的对象个数都是固定的，如果cc可以将这个返回的部分特殊处理的话，那么下次tc还需要这个部分的话，
那么就可以很快地进行分配，否则需要遍历如果freelist不够的话那么还需要从pageheap里面进行切片。而这个部分就叫做transfer cache.:)
了解了这些之后就可以看各个接口实现了。
</p>
</div>

</div>

<div id="outline-container-1-3-4-2" class="outline-5">
<h5 id="sec-1-3-4-2"><span class="section-number-5">1.3.4.2</span> Init</h5>
<div class="outline-text-5" id="text-1-3-4-2">

<p>init主要是计算了tc(transfer cache)的max_cache_size以及cache_size,然后初始化了字段。
我们这里暂时不关注empty以及nonempty这两个字段的数据结构
</p>


<pre class="src src-C++">void CentralFreeList::Init(size_t cl) {
  size_class_ = cl;
  tcmalloc::DLL_Init(&amp;empty_);
  tcmalloc::DLL_Init(&amp;nonempty_);
  num_spans_ = 0;
  counter_ = 0;

  max_cache_size_ = kMaxNumTransferEntries;
#ifdef TCMALLOC_SMALL_BUT_SLOW
  // Disable the transfer cache for the small footprint case.
  cache_size_ = 0;
#else
  cache_size_ = 16;
#endif
  if (cl &gt; 0) {
    int32_t bytes = Static::sizemap()-&gt;ByteSizeForClass(cl);
    int32_t objs_to_move = Static::sizemap()-&gt;num_objects_to_move(cl);
    max_cache_size_ = (min)(max_cache_size_,
                          (max)(1, (1024 * 1024) / (bytes * objs_to_move)));
    cache_size_ = (min)(cache_size_, max_cache_size_);
  }
  used_slots_ = 0;
  ASSERT(cache_size_ &lt;= max_cache_size_);
}
</pre>


</div>

</div>

<div id="outline-container-1-3-4-3" class="outline-5">
<h5 id="sec-1-3-4-3"><span class="section-number-5">1.3.4.3</span> InsertRange</h5>
<div class="outline-text-5" id="text-1-3-4-3">

<p>这个接口就是为了回收[start,end]并且长度为N objects的内存链。首先注意它加了自选锁确保了线程安全。
然后有一个逻辑就是判断是否可以进入tc,如果不允许进入tc的话那么挂到链上去。
</p>


<pre class="src src-C++">void CentralFreeList::InsertRange(void *start, void *end, int N) {
  SpinLockHolder h(&amp;lock_);
  if (N == Static::sizemap()-&gt;num_objects_to_move(size_class_) &amp;&amp;
    MakeCacheSpace()) { // &#36825;&#37324;&#27809;&#26377;&#30475;&#25026;MakeCacheSpace&#37324;&#38754;&#19968;&#20010;&#36923;&#36753;&#65292;&#25105;&#33258;&#24049;&#35273;&#24471;&#26159;&#26080;&#20851;&#32039;&#35201;&#30340;&#12290;
    // &#22240;&#20026;&#30475;&#19978;&#21435;&#20687;&#26159;&#25910;&#32553;&#20854;&#20182;&#30340;slab cc(EvictRandomSizeClass).
    // &#36825;&#37324;&#25105;&#20204;&#21487;&#20197;&#31616;&#21333;&#22320;&#35748;&#20026;&#65292;&#23427;&#23601;&#26159;&#22312;&#35745;&#31639;tc_slots&#37324;&#38754;&#26159;&#21542;&#26377;slot&#21487;&#20197;&#20998;&#37197;.
    int slot = used_slots_++;
    ASSERT(slot &gt;=0);
    ASSERT(slot &lt; max_cache_size_);
    TCEntry *entry = &amp;tc_slots_[slot]; // &#22914;&#26524;&#20998;&#37197;&#25104;&#21151;&#30340;&#35805;&#65292;&#37027;&#20040;&#30452;&#25509;&#25346;&#36733;.
    entry-&gt;head = start;
    entry-&gt;tail = end;
    return;
  }
  ReleaseListToSpans(start); // &#22914;&#26524;&#19981;&#20801;&#35768;&#25346;&#21040;tc&#30340;&#35805;&#65292;&#37027;&#20040;&#23601;&#38656;&#35201;&#21333;&#29420;&#22788;&#29702;.
}
</pre>


<p>
回收到tc这个逻辑非常简单，然后看看ReleaseListToSpans这个逻辑。大致逻辑就是遍历start知道end,
然后对于每一个object调用ReleaseToSpans单独进行处理。
</p>


<pre class="src src-C++">void CentralFreeList::ReleaseToSpans(void* object) {
  Span* span = MapObjectToSpan(object); // &#23558;object&#26144;&#23556;&#21040;span
  ASSERT(span != NULL);
  ASSERT(span-&gt;refcount &gt; 0);

  // If span is empty, move it to non-empty list
  if (span-&gt;objects == NULL) { // &#22914;&#26524;span&#19978;&#38754;&#27809;&#26377;&#20219;&#20309;free objects&#30340;&#35805;.
    tcmalloc::DLL_Remove(span); // &#37027;&#20040;&#23558;span&#20174;&#21407;&#26469;&#25346;&#36733;&#38142;&#34920;&#21024;&#38500;(empty).
    tcmalloc::DLL_Prepend(&amp;nonempty_, span); // &#25346;&#36733;&#21040;&#36825;&#20010;cc&#30340;nonempty&#38142;&#34920;&#19978;.
    Event(span, 'N', 0);
  }

  counter_++; // &#24403;&#21069;free objects&#22686;&#21152;&#20102;
  span-&gt;refcount--; // &#36825;&#20010;span&#30340;ref count&#20943;&#23569;&#20102;.
  // span refcount&#34920;&#31034;&#37324;&#38754;&#26377;&#22810;&#23569;&#20010;objects&#20998;&#37197;&#20986;&#21435;&#20102;.
  if (span-&gt;refcount == 0) { // &#22914;&#26524;==0&#30340;&#35805;&#65292;&#37027;&#20040;&#35828;&#26126;&#36825;&#20010;span&#21487;&#20197;&#22238;&#25910;&#20102;.
    Event(span, '#', 0);
    counter_ -= ((span-&gt;length&lt;&lt;kPageShift) /
                 Static::sizemap()-&gt;ByteSizeForClass(span-&gt;sizeclass));
    tcmalloc::DLL_Remove(span);
    --num_spans_;

    // Release central list lock while operating on pageheap
    lock_.Unlock();
    {
      SpinLockHolder h(Static::pageheap_lock());
      Static::pageheap()-&gt;Delete(span); // &#23558;span&#22238;&#25910;pageheap&#37324;&#38754;&#21435;&#65292;&#36825;&#20010;&#22320;&#26041;&#21487;&#33021;&#20250;&#36827;&#34892;&#20869;&#23384;&#21512;&#24182;
    }
    lock_.Lock();
  } else {
    // &#21542;&#21017;&#23601;&#23558;&#36825;&#20010;object&#25346;&#22312;span&#38142;&#19978;.
    *(reinterpret_cast&lt;void**&gt;(object)) = span-&gt;objects;
    span-&gt;objects = object;
  }
}
</pre>

<p>
这里有一个最重要的问题就是MapObjectToSpan,object是如何映射到span的。这里我们首先可以大致说一下，
就是tcmalloc因为是按照page来分配的，所以如果知道地址的话，那么其实就知道于第几个页。而span可以管理多个页，
这样的话就可以知道这个页是哪个span来管理的了。具体代码的话会在span管理部分说明。
</p>
</div>

</div>

<div id="outline-container-1-3-4-4" class="outline-5">
<h5 id="sec-1-3-4-4"><span class="section-number-5">1.3.4.4</span> RemoveRange</h5>
<div class="outline-text-5" id="text-1-3-4-4">

<p>这个接口就是为了尝试分配N个objects对象，然后将首地址尾地址给start和end.同样内部逻辑会判断是否可以从tc
中直接取出，如果可以取出的话那么分配就非常快。注意函数开始也尝试加锁了。
</p>


<pre class="src src-C++">int CentralFreeList::RemoveRange(void **start, void **end, int N) {
  ASSERT(N &gt; 0);
  lock_.Lock();
  if (N == Static::sizemap()-&gt;num_objects_to_move(size_class_) &amp;&amp;
      used_slots_ &gt; 0) { // &#22914;&#26524;&#21487;&#20197;&#30452;&#25509;&#20174;tc&#37324;&#38754;&#20998;&#37197;.
    int slot = --used_slots_;
    ASSERT(slot &gt;= 0);
    TCEntry *entry = &amp;tc_slots_[slot];
    *start = entry-&gt;head;
    *end = entry-&gt;tail;
    lock_.Unlock();
    return N;
  }

  int result = 0;
  void* head = NULL;
  void* tail = NULL;
  // TODO: Prefetch multiple TCEntries?
  tail = FetchFromSpansSafe(); // &#36923;&#36753;&#26159;&#39318;&#20808;&#25918;&#22312;&#23614;&#37096;,&#28982;&#21518;&#19981;&#26029;&#22320;&#22312;&#22836;&#37096;&#25340;&#25509;.
  if (tail != NULL) {
    SLL_SetNext(tail, NULL);
    head = tail;
    result = 1;
    while (result &lt; N) {
      void *t = FetchFromSpans();
      if (!t) break;
      SLL_Push(&amp;head, t);
      result++;
    }
  }
  lock_.Unlock();
  *start = head;
  *end = tail;
  return result;
}
</pre>


<p>
其中FetchFromSpanSafe逻辑也比较简单，就是
</p>


<pre class="src src-C++">void* CentralFreeList::FetchFromSpansSafe() {
  void *t = FetchFromSpans();
  if (!t) {
    Populate(); // &#23581;&#35797;&#36801;&#31227;
    t = FetchFromSpans();
  }
  return t;
}
</pre>


<p>
首先我们要看懂FetchFromSpans()逻辑，才能够清楚什么情况下面需要调用Populate
</p>


<pre class="src src-C++">void* CentralFreeList::FetchFromSpans() {
  if (tcmalloc::DLL_IsEmpty(&amp;nonempty_)) return NULL; // &#22914;&#26524;span&#37324;&#38754;&#37117;&#31354;&#20102;&#30340;.
  Span* span = nonempty_.next;

  ASSERT(span-&gt;objects != NULL);
  span-&gt;refcount++;
  void* result = span-&gt;objects; // &#21542;&#21017;&#23601;&#20250;&#20174;span&#37324;&#38754;&#20998;&#37197;object.
  span-&gt;objects = *(reinterpret_cast&lt;void**&gt;(result));
  if (span-&gt;objects == NULL) {
    // Move to empty list
    tcmalloc::DLL_Remove(span);
    tcmalloc::DLL_Prepend(&amp;empty_, span);
    Event(span, 'E', 0);
  }
  counter_--;
  return result;
}
</pre>


</div>

</div>

<div id="outline-container-1-3-4-5" class="outline-5">
<h5 id="sec-1-3-4-5"><span class="section-number-5">1.3.4.5</span> Populate</h5>
<div class="outline-text-5" id="text-1-3-4-5">

<p>基本上了解了调用Populate的时机，是如果cc里面nonempty里面没有span的话。代码有点长.
这里为了减少阻塞的部分，首先进行解锁然后让全局进行分配。只是针对局部操作没有任何问题。
最后加入nonempty的部分的话这个部分需要加锁。非常巧妙。
</p>


<pre class="src src-C++">void CentralFreeList::Populate() {
  // Release central list lock while operating on pageheap
  lock_.Unlock();  // &#39318;&#20808;&#38656;&#35201;&#35745;&#31639;&#20986;&#25105;&#20204;&#38656;&#35201;&#22810;&#23569;&#20010;pages
  const size_t npages = Static::sizemap()-&gt;class_to_pages(size_class_);

  Span* span;
  {
    SpinLockHolder h(Static::pageheap_lock());
    span = Static::pageheap()-&gt;New(npages); // &#20998;&#37197;&#21040;pages&#24471;&#21040;span.
    if (span) Static::pageheap()-&gt;RegisterSizeClass(span, size_class_);
  }
  if (span == NULL) {
    MESSAGE(<span class="org-string">"tcmalloc: allocation failed"</span>, npages &lt;&lt; kPageShift);
    lock_.Lock();
    return;
  }
  ASSERT(span-&gt;length == npages);
  for (int i = 0; i &lt; npages; i++) { // &#23558;span&#21644;size_class&#20043;&#38388;&#20851;&#32852;&#36215;&#26469;
    // &#24212;&#35813;&#26159;&#20026;&#20102;&#21518;&#38754;&#26597;&#25214;&#26041;&#20415;&#65292;&#20294;&#26159;&#29616;&#22312;&#36824;&#19981;&#30693;&#36947;&#26377;&#20160;&#20040;&#29992;&#36884;&#12290;&#20294;&#26159;&#19981;&#24433;&#21709;&#38405;&#35835;.
    Static::pageheap()-&gt;CacheSizeClass(span-&gt;start + i, size_class_);
  }

  // &#23545;&#36825;&#20010;span&#37324;&#38754;&#30340;&#25152;&#26377;objects&#32452;&#32455;&#25104;&#38142;&#34920;&#24418;&#24335;
  // Split the block into pieces and add to the free-list
  // TODO: coloring of objects to avoid cache conflicts?
  void** tail = &amp;span-&gt;objects;
  char* ptr = reinterpret_cast&lt;char*&gt;(span-&gt;start &lt;&lt; kPageShift);
  char* limit = ptr + (npages &lt;&lt; kPageShift);
  const size_t size = Static::sizemap()-&gt;ByteSizeForClass(size_class_);
  int num = 0;
  while (ptr + size &lt;= limit) {
    *tail = ptr;
    tail = reinterpret_cast&lt;void**&gt;(ptr);
    ptr += size;
    num++;
  }
  ASSERT(ptr &lt;= limit);
  *tail = NULL;
  span-&gt;refcount = 0; // No sub-object in use yet

  // &#23558;&#36825;&#20010;span&#21152;&#20837;nonempty&#38142;&#34920;&#30340;&#35805;&#38656;&#35201;&#21152;&#38145;&#12290;
  // Add span to list of non-empty spans
  lock_.Lock();
  tcmalloc::DLL_Prepend(&amp;nonempty_, span);
  ++num_spans_;
  counter_ += num;
}
</pre>


</div>
</div>

</div>

<div id="outline-container-1-3-5" class="outline-4">
<h4 id="sec-1-3-5"><span class="section-number-4">1.3.5</span> PageHeap</h4>
<div class="outline-text-4" id="text-1-3-5">

<p>page_heap.h
</p>

</div>

<div id="outline-container-1-3-5-1" class="outline-5">
<h5 id="sec-1-3-5-1"><span class="section-number-5">1.3.5.1</span> Data Structure</h5>
<div class="outline-text-5" id="text-1-3-5-1">

<p>PageHeap是在page_heap.h里面定义的，主要是用来分配page的。对于PageHeap结构还是比较复杂的.阅读tcmalloc文档也会发现，
管理page的方法和cc是一样的，也是按照page大小做成数组。每个数组的结构是这样的
</p>


<pre class="src src-C++">// We segregate spans of a given size into two circular linked
// lists: one for normal spans, and one for spans whose memory
// has been returned to the system.
struct SpanList {
  Span        normal;
  Span        returned; // &#20854;&#23454;&#23545;&#20110;&#36825;&#20010;&#37096;&#20998;&#27809;&#26377;&#24517;&#35201;&#21306;&#20998;&#30340;&#65292;&#22240;&#20026;&#20195;&#30721;&#37324;&#38754;&#22823;&#37096;&#20998;&#37117;&#26159;&#25346;&#22312;normal&#36825;&#20010;&#38142;&#19978;&#30340;&#12290;
};

// List of free spans of length &gt;= kMaxPages
SpanList large_; // &#23545;&#20110;&gt;=kMaxPages&#30340;&#39029;&#38754;&#21333;&#29420;&#32500;&#25252;&#19968;&#20010;free list.

// Array mapping from span length to a doubly linked list of free spans
SpanList free_[kMaxPages]; // &#38024;&#23545;&#27599;&#20010;&#39029;&#38754;&#22823;&#23567;&#20570;&#30340;free list.
</pre>

<p>
span的状态只有三种，一种是IN_USE表示正在被使用，一种表示ON_NORMAL_FREELIST表示放在了normal freelist上面。
另外一种是ON_RETURNED_FREELIST表示放在returned freelist上面。这里简单地说明一下normal freelist与returned freelist差别。
normal freelist是普通的回收进行缓存起来，而returned freelist表示已经完全unmmap回到系统内存部分了。不过因为实际并没有交回给系统内存，
所以这两个仅仅是概念上面的差别.
</p>

<p>
另外在PageHeap里面还定义了如何通过PageID查找到Span这个结构，使用了两种方式，一种是Cache,另外一种是radix tree(32位是另外一个结构). 这个会在下面分析
</p>


<pre class="src src-C++">// Selector class -- general selector uses 3-level map
template &lt;int BITS&gt; class MapSelector {
 public:
  typedef TCMalloc_PageMap3&lt;BITS-kPageShift&gt; Type;
  typedef PackedCache&lt;BITS-kPageShift, uint64_t&gt; CacheType;
};

  // Pick the appropriate map and cache types based on pointer size
  typedef MapSelector&lt;kAddressBits&gt;::Type PageMap;
  typedef MapSelector&lt;kAddressBits&gt;::CacheType PageMapCache;
  PageMap pagemap_;
  mutable PageMapCache pagemap_cache_;
</pre>

<p>
其中kAddressBits的定义在common.h
</p>


<pre class="src src-C++">#if defined __x86_64__
// All current and planned x86_64 processors only look at the lower 48 bits
// in virtual to physical address translation.  The top 16 are thus unused.
// TODO(rus): Under what operating systems can we increase it safely to 17?
// This lets us use smaller page maps.  On first allocation, a 36-bit page map
// uses only 96 KB instead of the 4.5 MB used by a 52-bit page map.
static const int kAddressBits = (sizeof(void*) &lt; 8 ? (8 * sizeof(void*)) : 48); // __x86_64__&#23601;&#26159;64&#20301;
#else
static const int kAddressBits = 8 * sizeof(void*);
#endif
</pre>


<p>
对于PageHeap比较重要的接口包括下面这些：
</p><ul>
<li>Span* New(Length n); // 分配n个pages并且返回Span对象
</li>
<li>void Delete(Span* span); // 删除Span对象管理的内存
</li>
<li>void RegisterSizeClass(Span* span, size_t sc); // 注册这个span对象管理的slab大小多少(0表示不是用于分配小内存)
</li>
<li>Span* Split(Span* span, Length n); // 将当前的span切分，一个管理n个页面的span,一个是剩余的。
</li>
<li>inline Span* GetDescriptor(PageID p) const //根据PageID得到管理这个Page的Span对象
</li>
<li>void Dump(TCMalloc_Printer* out); // Dump出PageHeap信息
</li>
<li>bool GetNextRange(PageID start, base::MallocRange* r); // 如果page heap管理了&gt;=start的span,那么返回这个信息
</li>
<li>Length ReleaseAtLeastNPages(Length num_pages); // 尝试至少释放num_pages个页面
</li>
<li>size_t GetSizeClassIfCached(PageID p) // 在cache中返回这个page id对应的slab class
</li>
<li>void CacheSizeClass(PageID p, size_t cl) // 在cache中存放page id对应的slab class.
</li>
</ul>

<p>这里有一个点可能有疑问，就是为什么span需要上面标记slab class.原因非常简单，就是如果用户在释放内存的时候，根据ptr查找到对应的span.
然后肯定想知道这个ptr到底应该如何归还，本身带有多少内存。此外还需要注意的是，对于page来说的话，一共管理了(kMaxPages)种页面大小。
tcmalloc代码里面kMaxPages==1 &lt;&lt; (20- kPageShift) 相同于有256种页面。但是最后一种页面大小的话可以超过255 pages,这样才可以用于分配大内存。
</p>
</div>

</div>

<div id="outline-container-1-3-5-2" class="outline-5">
<h5 id="sec-1-3-5-2"><span class="section-number-5">1.3.5.2</span> New</h5>
<div class="outline-text-5" id="text-1-3-5-2">

<p>New的逻辑非常简单，首先会尝试在free list里面查找，如果没有的话在lage free list里面查找，不行的话尝试要更多的内存，然后重试。
需要注意的是，因为这个是一个全局的操作，所以前面都会加上自选锁 SpinLockHolder h(Static::pageheap_lock());
</p>


<pre class="src src-C++">Span* PageHeap::New(Length n) {
  ASSERT(Check());
  ASSERT(n &gt; 0);

  Span* result = SearchFreeAndLargeLists(n);  // free list&#28982;&#21518;&#22312;large&#37324;&#38754;&#26597;&#25214;
  if (result != NULL)
    return result;

  // Grow the heap and try again.
  if (!GrowHeap(n)) { // &#19981;&#34892;&#30340;&#35805;&#23581;&#35797;&#20998;&#37197;&#26356;&#22810;&#20869;&#23384;
    ASSERT(Check());
    return NULL;
  }
  return SearchFreeAndLargeLists(n); // &#28982;&#21518;&#37325;&#26032;&#23581;&#35797;&#20998;&#37197;
}
</pre>


<p>
SearchFreeAndLargeLists相对来说还是比较简单的，但是里面Carve这个需要单独来看
</p>


<pre class="src src-C++">Span* PageHeap::SearchFreeAndLargeLists(Length n) {
  ASSERT(Check());
  ASSERT(n &gt; 0);

  // Find first size &gt;= n that has a non-empty list
  for (Length s = n; s &lt; kMaxPages; s++) { // &#36941;&#21382;&#25152;&#26377;&#30340;Pages&#30475;&#30475;&#26159;&#21542;&#26377;&#21512;&#36866;&#30340;&#12290;
    Span* ll = &amp;free_[s].normal;
    // If we're lucky, ll is non-empty, meaning it has a suitable span.
    if (!DLL_IsEmpty(ll)) {
      ASSERT(ll-&gt;next-&gt;location == Span::ON_NORMAL_FREELIST);
      return Carve(ll-&gt;next, n); // &#22914;&#26524;&#26377;&#21512;&#36866;&#30340;&#35805;&#65292;&#37027;&#20040;&#21487;&#33021;&#38656;&#35201;&#20999;&#21106;&#19968;&#19979;,&#20174;&#37324;&#38754;&#20999;&#21106;&#20986;n pages&#20986;&#26469;
    }
    // Alternatively, maybe there's a usable returned span.
    ll = &amp;free_[s].returned;
    if (!DLL_IsEmpty(ll)) {
      ASSERT(ll-&gt;next-&gt;location == Span::ON_RETURNED_FREELIST);
      return Carve(ll-&gt;next, n);
    }
  }
  // No luck in free lists, our last chance is in a larger class.
  return AllocLarge(n);  // May be NULL // &#22914;&#26524;&#27809;&#26377;&#20998;&#37197;&#25104;&#21151;&#30340;&#35805;&#37027;&#20040;&#20174;AllocLarge&#37324;&#38754;&#20998;&#37197;
}
</pre>

<p>
对于AllocLarge部分的话非常简单，就是使用最佳匹配算法。完了之后调用Carve同样进行切割。这里就不贴出代码详细分析。
</p>
</div>

</div>

<div id="outline-container-1-3-5-3" class="outline-5">
<h5 id="sec-1-3-5-3"><span class="section-number-5">1.3.5.3</span> Carve</h5>
<div class="outline-text-5" id="text-1-3-5-3">

<p>我们看看Carve代码，然后在里面的话会稍微粗略地提到pagemap管理span对象的细节
</p>


<pre class="src src-C++">Span* PageHeap::Carve(Span* span, Length n) {
  ASSERT(n &gt; 0);
  ASSERT(span-&gt;location != Span::IN_USE);
  const int old_location = span-&gt;location;
  RemoveFromFreeList(span); // &#20174;freelist&#37324;&#38754;&#21024;&#38500;&#65292;&#21516;&#26102;&#35760;&#24405;&#20449;&#24687;&#20063;&#20250;&#26356;&#25913;&#12290;
  span-&gt;location = Span::IN_USE; // &#20462;&#25913;&#19968;&#19979;location.
  Event(span, 'A', n);

  const int extra = span-&gt;length - n;
  ASSERT(extra &gt;= 0);
  if (extra &gt; 0) {
    Span* leftover = NewSpan(span-&gt;start + n, extra); // &#21019;&#24314;&#19968;&#20010;&#26032;&#30340;span&#23545;&#35937;
    leftover-&gt;location = old_location; // &#36825;&#20010;&#26032;&#30340;&#23545;&#35937;&#37324;&#38754;&#23384;&#25918;&#21040;&#26159;&#21407;&#26469;location.
    Event(leftover, 'S', extra);
    RecordSpan(leftover); // &#23558;&#21097;&#20313;&#30340;span&#35760;&#24405;&#19979;&#26469;&#24182;&#19988;&#25554;&#20837;&#21040;free list&#37324;&#38754;.
    PrependToFreeList(leftover);  // Skip coalescing - no candidates possible
    span-&gt;length = n;
    pagemap_.set(span-&gt;start + n - 1, span); // &#21516;&#26102;&#26631;&#35760;span&#31649;&#29702;&#30340;&#33539;&#22260;.
  }
  ASSERT(Check());
  return span;
}
</pre>


<p>
逻辑可以说非常简单，但是如果之前看过文档的话需要知道这里面pagemap为什么需要set.
非常简单，如果span管理的是[p..q]的范围的话，那么在pagemap里面只需要记录(p,span),(q,span).
这样如果有一个span回收的话，那么在pagemap里面查找p-1和q+1的span,然后尝试合并。非常精巧。
所以在RecordSpan里面很明显就是需要设置前后的边界
</p>


<pre class="src src-C++">void RecordSpan(Span* span) {
  pagemap_.set(span-&gt;start, span); // &#36825;&#26102;span&#24320;&#22987;
  if (span-&gt;length &gt; 1) {
    pagemap_.set(span-&gt;start + span-&gt;length - 1, span); // &#35774;&#32622;span&#32467;&#26463;
  }
}
</pre>


</div>

</div>

<div id="outline-container-1-3-5-4" class="outline-5">
<h5 id="sec-1-3-5-4"><span class="section-number-5">1.3.5.4</span> GrowHeap</h5>
<div class="outline-text-5" id="text-1-3-5-4">

<p>GrowHeap就是需要尝试从系统中拿出更多的内存出来然后好做切分，满足本次allocate n pages的请求。
GrowHeap里面有一些策略
</p>


<pre class="src src-C++">// &#36825;&#20010;&#23601;&#26159;&#30456;&#24403;&#20110;&#20801;&#35768;&#20998;&#37197;&#30340;&#26368;&#22823;Pages
static const Length kMaxValidPages = (~static_cast&lt;Length&gt;(0)) &gt;&gt; kPageShift;
static const int kMinSystemAlloc = kMaxPages; // &#35843;&#29992;GrowHeap&#26368;&#23567;&#30340;&#39029;&#25968;

bool PageHeap::GrowHeap(Length n) {
  ASSERT(kMaxPages &gt;= kMinSystemAlloc);
  if (n &gt; kMaxValidPages) return false;
  Length ask = (n&gt;kMinSystemAlloc) ? n : static_cast&lt;Length&gt;(kMinSystemAlloc); // &#20250;&#21028;&#26029;&#26159;&#21542;&#36229;&#36807;&#65292;&#22914;&#26524;&#27809;&#26377;&#36229;&#36807;&#30340;&#35805;&#65292;
  // &#37027;&#20040;&#25353;&#29031;kMinSystemAlloc&#20998;&#37197;
  size_t actual_size;
  void* ptr = TCMalloc_SystemAlloc(ask &lt;&lt; kPageShift, &amp;actual_size, kPageSize);
  if (ptr == NULL) {
    if (n &lt; ask) {
      // Try growing just <span class="org-string">"n"</span> pages
      ask = n;
      ptr = TCMalloc_SystemAlloc(ask &lt;&lt; kPageShift, &amp;actual_size, kPageSize); // &#22914;&#26524;ask&#20998;&#37197;&#19981;&#20102;&#65292;&#37027;&#20040;&#23581;&#35797;&#20998;&#37197;n
    }
    if (ptr == NULL) return false;
  }
  ask = actual_size &gt;&gt; kPageShift;
  RecordGrowth(ask &lt;&lt; kPageShift); // TODO.???

  uint64_t old_system_bytes = stats_.system_bytes;
  stats_.system_bytes += (ask &lt;&lt; kPageShift);
  const PageID p = reinterpret_cast&lt;uintptr_t&gt;(ptr) &gt;&gt; kPageShift;
  ASSERT(p &gt; 0);

  // If we have already a lot of pages allocated, just pre allocate a bunch of
  // memory for the page map. This prevents fragmentation by pagemap metadata
  // when a program keeps allocating and freeing large blocks.

  //  static const size_t kPageMapBigAllocationThreshold = 128 &lt;&lt; 20;(128MB)
  // &#36825;&#20010;&#22320;&#26041;&#21028;&#26029;&#65292;&#36825;&#27425;&#20998;&#37197;&#26159;&#19981;&#26159;&#24050;&#32463;&#36234;&#36807;&#20102;&#19968;&#20010;threshold
  // &#22914;&#26524;&#36234;&#36807;&#30340;&#35805;&#65292;&#37027;&#20040;&#24847;&#21619;&#30528;pagemap&#37324;&#38754;&#21487;&#33021;&#38656;&#35201;&#20998;&#37197;&#26356;&#22810;&#30340;&#20869;&#23384;
  // &#20294;&#26159;&#23545;&#20110;64&#20301;&#26469;&#35828;&#30340;&#35805;&#65292;&#37324;&#38754;&#27809;&#26377;&#20219;&#20309;&#36923;&#36753;.
  if (old_system_bytes &lt; kPageMapBigAllocationThreshold
      &amp;&amp; stats_.system_bytes &gt;= kPageMapBigAllocationThreshold) {
    pagemap_.PreallocateMoreMemory();
  }

  // Make sure pagemap_ has entries for all of the new pages.
  // Plus ensure one before and one after so coalescing code
  // does not need bounds-checking.
  if (pagemap_.Ensure(p-1, ask+2)) {   // &#22240;&#20026;&#38656;&#35201;&#25554;&#20837;&#26032;&#30340;span,&#25152;&#20197;&#24517;&#39035;&#30830;&#20445;&#36825;&#20010;pagemap&#30830;&#23454;&#23384;&#22312;.
    // Pretend the new area is allocated and then Delete() it to cause
    // any necessary coalescing to occur.
    Span* span = NewSpan(p, ask);
    RecordSpan(span);
    Delete(span); // &#23558;&#36825;&#20010;Span&#36820;&#22238;&#32473;large_&#37324;&#31561;&#24453;&#19979;&#27425;&#20998;&#37197;
    ASSERT(Check());
    return true;
  } else {
    // We could not allocate memory within <span class="org-string">"pagemap_"</span>
    // TODO: Once we can return memory to the system, return the new span
    return false;
  }
}
</pre>


</div>

</div>

<div id="outline-container-1-3-5-5" class="outline-5">
<h5 id="sec-1-3-5-5"><span class="section-number-5">1.3.5.5</span> Delete</h5>
<div class="outline-text-5" id="text-1-3-5-5">

<p>Delete逻辑非常简单
</p>


<pre class="src src-C++">void PageHeap::Delete(Span* span) {
  ASSERT(Check());
  ASSERT(span-&gt;location == Span::IN_USE);
  ASSERT(span-&gt;length &gt; 0);
  ASSERT(GetDescriptor(span-&gt;start) == span);
  ASSERT(GetDescriptor(span-&gt;start + span-&gt;length - 1) == span);
  const Length n = span-&gt;length;
  span-&gt;sizeclass = 0;
  span-&gt;sample = 0;
  span-&gt;location = Span::ON_NORMAL_FREELIST;
  Event(span, 'D', span-&gt;length);
  MergeIntoFreeList(span);  // Coalesces if possible // &#20250;&#23581;&#35797;&#36827;&#34892;&#21512;&#24182;
  IncrementalScavenge(n); // &#22686;&#37327;&#25910;&#38598;. &#21518;&#38754;&#20250;&#20180;&#32454;&#30475;&#36825;&#20010;&#20989;&#25968;&#30340;&#23450;&#20041;
  ASSERT(Check());
}
</pre>


<p>
里面有两个函数我们需要仔细关心MergeIntoFreeList以及IncrementalScavenge.首先看看MergeIntoFreeList
</p>


<pre class="src src-C++">void PageHeap::MergeIntoFreeList(Span* span) {
  ASSERT(span-&gt;location != Span::IN_USE);
  const PageID p = span-&gt;start;
  const Length n = span-&gt;length;
  // &#39318;&#20808;&#23581;&#35797;&#21512;&#24182;p-1 pages&#36825;&#20010;span
  Span* prev = GetDescriptor(p-1);
  if (prev != NULL &amp;&amp; prev-&gt;location == span-&gt;location) {
    // Merge preceding span into this span
    ASSERT(prev-&gt;start + prev-&gt;length == p);
    const Length len = prev-&gt;length;
    RemoveFromFreeList(prev);
    DeleteSpan(prev);
    span-&gt;start -= len;
    span-&gt;length += len;
    pagemap_.set(span-&gt;start, span);
    Event(span, 'L', len);
  }
 // &#28982;&#21518;&#23581;&#35797;&#21512;&#24182;p+n pages&#36825;&#20010;span.
  Span* next = GetDescriptor(p+n);
  if (next != NULL &amp;&amp; next-&gt;location == span-&gt;location) {
    // Merge next span into this span
    ASSERT(next-&gt;start == p+n);
    const Length len = next-&gt;length;
    RemoveFromFreeList(next);
    DeleteSpan(next);
    span-&gt;length += len;
    pagemap_.set(span-&gt;start + span-&gt;length - 1, span);
    Event(span, 'R', len);
  }
  // &#21512;&#24182;&#23436;&#25104;&#20043;&#21518;&#23601;&#20250;&#25918;&#20837;free list&#37324;&#38754;&#21435;
  PrependToFreeList(span);
}
</pre>


</div>

</div>

<div id="outline-container-1-3-5-6" class="outline-5">
<h5 id="sec-1-3-5-6"><span class="section-number-5">1.3.5.6</span> IncrementalScavenge</h5>
<div class="outline-text-5" id="text-1-3-5-6">

<p>IncrementalScavenge这个意思就是增量回收，大致内容就是说将一部分的页面交回给系统内存。虽然在tcmalloc里面实现并没有完全交回给系统内存，
而只是简单地挂在了_returned_free_list上面，但是里面的策略还是值得看看的。这里所谓的scavenge_counter_意思就是如果归还了多少内存之后，
那么我们就会尝试进行一次完全交回给系统内存.
</p>



<pre class="src src-C++">void PageHeap::IncrementalScavenge(Length n) {
  // Fast path; not yet time to release memory
  scavenge_counter_ -= n;
  if (scavenge_counter_ &gt;= 0) return;  // Not yet time to scavenge

  // &#40664;&#35748;&#20540;&#30340;&#35805;&#26159;1.0,&#36825;&#20010;&#21487;&#20197;&#26377;&#29615;&#22659;&#21464;&#37327;&#35774;&#32622;.
  // &#22914;&#26524;&#22238;&#25910;&#29575;&#24456;&#20302;&#30340;&#21704;&#65292;&#37027;&#20040;&#30456;&#24403;&#20110;&#19981;&#20250;&#24402;&#36824;&#32473;&#31995;&#32479;&#20869;&#23384;
  const double rate = FLAGS_tcmalloc_release_rate;
  if (rate &lt;= 1e-6) {
    // Tiny release rate means that releasing is disabled.
    //   static const int kDefaultReleaseDelay = 1 &lt;&lt; 18;
    scavenge_counter_ = kDefaultReleaseDelay;
    return;
  }

  // &#23581;&#35797;&#33267;&#24402;&#36824;&#19968;&#20010;&#39029;&#38754;.
  // &#20855;&#20307;&#36825;&#20010;&#20989;&#25968;&#23454;&#29616;&#22312;&#21518;&#38754;&#20250;&#25552;&#21040;.
  Length released_pages = ReleaseAtLeastNPages(1);

  // &#22914;&#26524;&#23454;&#38469;&#19978;&#27809;&#26377;&#24402;&#36824;&#30340;&#35805;&#65292;&#37027;&#20040;&#19979;&#27425;&#38656;&#35201;&#31561;&#24453;&#36825;&#20040;&#22810;&#27425;&#20043;&#21518;&#23581;&#35797;&#24402;&#36824;.
  if (released_pages == 0) {
    // Nothing to scavenge, delay for a while.
    scavenge_counter_ = kDefaultReleaseDelay;
  } else { // &#21542;&#21017;&#20250;&#25353;&#29031;&#19968;&#23450;&#30340;&#31574;&#30053;&#35774;&#23450;&#27425;&#25968;&#28982;&#21518;&#23581;&#35797;&#24402;&#36824;
    // Compute how long to wait until we return memory.
    // FLAGS_tcmalloc_release_rate==1 means wait for 1000 pages
    // after releasing one page.
    const double mult = 1000.0 / rate;
    double wait = mult * static_cast&lt;double&gt;(released_pages);
    if (wait &gt; kMaxReleaseDelay) {
      // Avoid overflow and bound to reasonable range.
       // static const int kMaxReleaseDelay = 1 &lt;&lt; 20;
      wait = kMaxReleaseDelay;
    }
    scavenge_counter_ = static_cast&lt;int64_t&gt;(wait);
  }
}
</pre>


</div>

</div>

<div id="outline-container-1-3-5-7" class="outline-5">
<h5 id="sec-1-3-5-7"><span class="section-number-5">1.3.5.7</span> ReleaseAtLeastNPages</h5>
<div class="outline-text-5" id="text-1-3-5-7">

<p>这个函数的语义就是至少尝试释放n pages.实现方式非常简单，每次都从一种pages里面取出一个东西并且进行释放，直到全部释放为止。
算是一种round-robin的方式吧，我猜想这样释放的方式对于后面分配的性能影响比较小，每一种大小都释放一些。
</p>


<pre class="src src-C++">Length PageHeap::ReleaseAtLeastNPages(Length num_pages) {
  Length released_pages = 0;
  Length prev_released_pages = -1;

  // Round robin through the lists of free spans, releasing the last
  // span in each list.  Stop after releasing at least num_pages.
  while (released_pages &lt; num_pages) {
    if (released_pages == prev_released_pages) { // &#22914;&#26524;&#33258;&#19978;&#27425;&#20381;&#36182;&#27809;&#26377;&#22810;&#20313;&#37322;&#25918;&#30340;&#35805;
      // Last iteration of while loop made no progress.
      break;
    }
    prev_released_pages = released_pages;

    for (int i = 0; i &lt; kMaxPages+1 &amp;&amp; released_pages &lt; num_pages;
         i++, release_index_++) { // &#27599;&#20010;&#22823;&#23567;&#31867;&#22411;&#37117;&#20250;&#23581;&#35797;&#37322;&#25918;&#19968;&#20010;.
      if (release_index_ &gt; kMaxPages) release_index_ = 0;
      SpanList* slist = (release_index_ == kMaxPages) ?
          &amp;large_ : &amp;free_[release_index_];
      if (!DLL_IsEmpty(&amp;slist-&gt;normal)) {
        Length released_len = ReleaseLastNormalSpan(slist);
        released_pages += released_len;
      }
    }
  }
  return released_pages;
}
</pre>


<p>
然后我们看看ReleaseLastNormalSpan这个过程，非常简单
</p>


<pre class="src src-C++">Length PageHeap::ReleaseLastNormalSpan(SpanList* slist) {
  Span* s = slist-&gt;normal.prev;
  ASSERT(s-&gt;location == Span::ON_NORMAL_FREELIST);
  RemoveFromFreeList(s); // &#20174;&#24403;&#21069;&#38142;&#20013;&#37322;&#25918;&#25481;.
  const Length n = s-&gt;length;
  // &#23454;&#38469;&#19978;&#36825;&#20010;&#37096;&#20998;&#24182;&#27809;&#26377;&#37322;&#25918;&#21734;.
  TCMalloc_SystemRelease(reinterpret_cast&lt;void*&gt;(s-&gt;start &lt;&lt; kPageShift),
                         static_cast&lt;size_t&gt;(s-&gt;length &lt;&lt; kPageShift));
  s-&gt;location = Span::ON_RETURNED_FREELIST; // &#26631;&#35760;&#20026;returned&#29366;&#24577;
   // &#20002;&#22238;return free list&#26102;&#20505;&#20250;&#23581;&#35797;&#21512;&#24182;.
  MergeIntoFreeList(s);  // Coalesces if possible.
  return n;
}
</pre>


</div>

</div>

<div id="outline-container-1-3-5-8" class="outline-5">
<h5 id="sec-1-3-5-8"><span class="section-number-5">1.3.5.8</span> Split</h5>
<div class="outline-text-5" id="text-1-3-5-8">

<p>Split过程和Carve过程是非常相似的，只不过Split针对的是IN_USE状态的这种span.
代码阅读到这里暂时还不知道这个Split什么时候调用:(.what a shame.
</p>
</div>

</div>

<div id="outline-container-1-3-5-9" class="outline-5">
<h5 id="sec-1-3-5-9"><span class="section-number-5">1.3.5.9</span> GetNextRange</h5>
<div class="outline-text-5" id="text-1-3-5-9">

<p>得到page id &gt;=start的span的具体内容。首先看看MallocRange的内容
</p>


<pre class="src src-C++">struct MallocRange {
  // &#36825;&#20010;malloc&#33539;&#22260;&#26159;&#20160;&#20040;&#31867;&#22411;
  enum Type {
    INUSE,                // Application is using this range
    FREE,                 // Range is currently free
    UNMAPPED,             // Backing physical memory has been returned to the OS
    UNKNOWN,
    // More enum values may be added in the future
  };
  // &#22320;&#22336;&#65292;&#38271;&#24230;&#65292;&#31867;&#22411;
  uintptr_t address;    // Address of range
  size_t length;        // Byte length of range
  Type type;            // Type of this range
  // =0 !INUSE,&#22914;&#26524;=1&#34920;&#31034;&#36825;&#20010;&#34987;&#24403;&#20570;page&#20351;&#29992;
  // &#22914;&#26524;[0,1]&#20043;&#38388;&#30340;&#35805;&#65292;&#34920;&#26126;&#34987;&#20570;&#25104;&#20102;&#23567;&#23545;&#35937;&#20998;&#37197;
  double fraction;      // Fraction of range that is being used (0 if !INUSE)
};
</pre>

<p>
然后来看看这个过程
</p>


<pre class="src src-C++">bool PageHeap::GetNextRange(PageID start, base::MallocRange* r) {
  Span* span = reinterpret_cast&lt;Span*&gt;(pagemap_.Next(start));
  if (span == NULL) {
    return false;
  }
  r-&gt;address = span-&gt;start &lt;&lt; kPageShift;
  r-&gt;length = span-&gt;length &lt;&lt; kPageShift;
  r-&gt;fraction = 0;
  switch (span-&gt;location) {
    case Span::IN_USE:
      r-&gt;type = base::MallocRange::INUSE;
      r-&gt;fraction = 1;
      if (span-&gt;sizeclass &gt; 0) {
        // Only some of the objects in this span may be in use.
        const size_t osize = Static::sizemap()-&gt;class_to_size(span-&gt;sizeclass); // &#39318;&#20808;&#30693;&#36947;&#36825;&#20010;class&#27599;&#20010;object size&#22810;&#23569;
       // refcount&#34920;&#31034;&#24050;&#32463;&#20351;&#29992;&#20102;&#22810;&#23569;&#20010;objects.,&#36825;&#26679;&#23601;&#21487;&#20197;&#24471;&#21040;&#20351;&#29992;&#29575;
        r-&gt;fraction = (1.0 * osize * span-&gt;refcount) / r-&gt;length;
      }
      break;
    case Span::ON_NORMAL_FREELIST:
      r-&gt;type = base::MallocRange::FREE;
      break;
    case Span::ON_RETURNED_FREELIST:
      r-&gt;type = base::MallocRange::UNMAPPED;
      break;
    default:
      r-&gt;type = base::MallocRange::UNKNOWN;
      break;
  }
  return true;
}
</pre>


</div>
</div>

</div>

<div id="outline-container-1-3-6" class="outline-4">
<h4 id="sec-1-3-6"><span class="section-number-4">1.3.6</span> TCMalloc_PageMap3</h4>
<div class="outline-text-4" id="text-1-3-6">

<p>page_map.h
</p>
<p>
之前pageheap里面可以看到有这么一个要求，就是从一个page ID映射到span这么一个过程。在64位下面的话逻辑地址空间有1 &lt;&lt; 64，
如果按照4K per page计算的话，那么最多会存在1&lt;&lt;52个page.如果使用数组存储的话那么是会存在问题的。所以这里使用了radix tree来进行映射。
对于64位的话使用了3-level radix tree.每段分别是(18,18,16)
</p>


<pre class="src src-C++">// How many bits should we consume at each interior level
static const int INTERIOR_BITS = (BITS + 2) / 3; // Round-up
static const int INTERIOR_LENGTH = 1 &lt;&lt; INTERIOR_BITS;

// How many bits should we consume at leaf level
static const int LEAF_BITS = BITS - 2*INTERIOR_BITS;
static const int LEAF_LENGTH = 1 &lt;&lt; LEAF_BITS;
</pre>

<p>
对于一个地址映射称为每一个level的number index的函数可以参看get这个方法
</p>


<pre class="src src-C++">void* get(Number k) const {
  const Number i1 = k &gt;&gt; (LEAF_BITS + INTERIOR_BITS);
  const Number i2 = (k &gt;&gt; LEAF_BITS) &amp; (INTERIOR_LENGTH-1);
  const Number i3 = k &amp; (LEAF_LENGTH-1);
  if ((k &gt;&gt; BITS) &gt; 0 ||
      root_-&gt;ptrs[i1] == NULL || root_-&gt;ptrs[i1]-&gt;ptrs[i2] == NULL) {
    return NULL;
  }
  return reinterpret_cast&lt;Leaf*&gt;(root_-&gt;ptrs[i1]-&gt;ptrs[i2])-&gt;values[i3];
}
</pre>

<p>
初次之外，这个pagemap还有两个比较重要的接口
</p><ul>
<li>bool Ensure(Number start, size_t n)
</li>
</ul>

<p>因为get,set接口的话都是假设每一层对应的array都是存在的，所以基本上在调用之前的话都必须确保这个array存在。
而Ensure就是做这件事情的，确保[start,start+n-1]这些PageId对应的每一层array都存在。
</p>
<ul>
<li>void* Next(Number k) const
</li>
</ul>

<p>Next接口就纯粹想知道&gt;=k的这些PageId首先映射到的span对象是什么，实现起来非常巧妙可以仔细阅读一下
</p>


<pre class="src src-C++">void* Next(Number k) const {
  while (k &lt; (Number(1) &lt;&lt; BITS)) {
    const Number i1 = k &gt;&gt; (LEAF_BITS + INTERIOR_BITS);
    const Number i2 = (k &gt;&gt; LEAF_BITS) &amp; (INTERIOR_LENGTH-1);
    if (root_-&gt;ptrs[i1] == NULL) { // &#22914;&#26524;&#36825;&#23618;&#20026;&#31354;&#30340;&#35805;&#65292;&#37027;&#20040;&#30452;&#25509;&#36339;&#21040;&#19979;&#19968;&#23618;
      // Advance to next top-level entry
      k = (i1 + 1) &lt;&lt; (LEAF_BITS + INTERIOR_BITS);
    } else {
      Leaf* leaf = reinterpret_cast&lt;Leaf*&gt;(root_-&gt;ptrs[i1]-&gt;ptrs[i2]);
      if (leaf != NULL) {
        for (Number i3 = (k &amp; (LEAF_LENGTH-1)); i3 &lt; LEAF_LENGTH; i3++) { // &#36941;&#21382;&#36825;&#19968;&#23618;(&#31532;&#19977;&#23618;)&#30475;&#30475;&#26159;&#21542;&#23384;&#22312;.
          if (leaf-&gt;values[i3] != NULL) {
            return leaf-&gt;values[i3];
          }
        }
      }
      // Advance to next interior entry
      k = ((k &gt;&gt; LEAF_BITS) + 1) &lt;&lt; LEAF_BITS; // &#22914;&#26524;&#31532;&#20108;&#23618;&#20026;&#31354;&#30340;&#35805;&#65292;&#37027;&#20040;&#21516;&#26679;&#36827;&#20837;&#19979;&#19968;&#23618;.
    }
  }
  return NULL;
}
</pre>


</div>

</div>

<div id="outline-container-1-3-7" class="outline-4">
<h4 id="sec-1-3-7"><span class="section-number-4">1.3.7</span> PackedCache</h4>
<div class="outline-text-4" id="text-1-3-7">

<p>packed-cache-inl.h
</p>
<p>
PackedCache是一种非常精巧的数据结构。它的作用主要是想知道对于一个pageId所管理的span而言的话，对应的sizeclass是什么。
在pageheap里面是这样定义的   typedef PackedCache&lt;BITS-kPageShift, uint64_t&gt; CacheType;  我们还是看看这个结构是什么样的
</p>


<pre class="src src-C++">template &lt;int kKeybits, typename T&gt;
class PackedCache {
 public:
  typedef uintptr_t K;
  typedef size_t V;
#ifdef TCMALLOC_SMALL_BUT_SLOW
  // Decrease the size map cache if running in the small memory mode.
  static const int kHashbits = 12;
#else
  static const int kHashbits = 16;
#endif
  // array_ is the cache.  Its elements are volatile because any
  // thread can write any array element at any time.
  volatile T array_[1 &lt;&lt; kHashbits];
};
</pre>

<p>
首先它还是一个KV结构，只不过K+V大小可以放在sizeof(T)字节里面。回顾一下对于64位而言，PageId 52位，而sizeclass只有85中，完全可以存放在sizeof(uint64_t)里面。
将K放在高字节，而V放在低字节，组成一个&lt;sizeof(uint64_t)大小的值存放在array_里面。此外还需要注意一个问题就是，这个有可能被多线程访问，
但是如果我们将这个内容设置称为volatile的话，那么是不需要加锁就可以完成的。
</p>
</div>

</div>

<div id="outline-container-1-3-8" class="outline-4">
<h4 id="sec-1-3-8"><span class="section-number-4">1.3.8</span> Thread Cache</h4>
<div class="outline-text-4" id="text-1-3-8">

<p>thread_cache.h
</p>

</div>

<div id="outline-container-1-3-8-1" class="outline-5">
<h5 id="sec-1-3-8-1"><span class="section-number-5">1.3.8.1</span> Data Structure</h5>
<div class="outline-text-5" id="text-1-3-8-1">

<p>Thread Cache就是每一个线程里面管理小对象分配的cache.tcmalloc应该是假设局部线程里面通常分配的都是小对象，这样可以减少锁竞争。
而如果是分配大对象的话，那么会直接从page heap里面进行分配。如果本地小对象不够的话，那么会尝试从central cache里面要。
Thread Cache比较重要的接口有下面这些：
</p><ul>
<li>void Init(pthread_t tid); // 初始化
</li>
<li>void Cleanup();
</li>
<li>void* Allocate(size_t size, size_t cl); // 从class里面分配size大小
</li>
<li>void Deallocate(void* ptr, size_t size_class); // 将ptr放回class对应slab里面
</li>
<li>void Scavenge(); // 回收内存到central cache.就是文档里面说的GC
</li>
<li>bool SampleAllocation(size_t k); // 是否认为这次分配的k字节需要进行采样.
</li>
</ul>

<p>还有一些静态方法也非常值得关注
</p><ul>
<li>InitModule // 初始化模块
</li>
<li>InitTSD // 初始化thread storage data.
</li>
<li>GetThreadHeap // thread cache.
</li>
<li>GetCache // tc
</li>
<li>GetCacheIfPresent // tc
</li>
<li>CreateCacheIfNecessary // 如果tc不存在就创建
</li>
<li>BecomeIdle // 标记这个thread已经idle，所以可以释放这个tc了
</li>
</ul>


<p>
涉及到的静态变量有下面这些
</p>


<pre class="src src-C++">namespace tcmalloc {

static bool phinited = false;

volatile size_t ThreadCache::per_thread_cache_size_ = kMaxThreadCacheSize; // &#27599;&#20010;tc&#30340;&#22823;&#23567; (4 &lt;&lt; 20,4MB)
size_t ThreadCache::overall_thread_cache_size_ = kDefaultOverallThreadCacheSize;// &#25152;&#26377;tc&#22823;&#23567; (8 * kMaxThreadCacheSize = 32MB)
ssize_t ThreadCache::unclaimed_cache_space_ = kDefaultOverallThreadCacheSize;  // &#31649;&#29702;&#23545;&#35937;&#25152;&#25345;&#26377;&#30340;tc&#22823;&#23567;(&#30456;&#24403;&#20110;&#24635;tc&#37324;&#38754;&#36824;&#26377;&#22810;&#23569;&#21487;&#29992;).
// (= overall_thread_cache_size_ - sum(tc.max_size))
PageHeapAllocator&lt;ThreadCache&gt; threadcache_allocator; // tc sample alloc.
ThreadCache* ThreadCache::thread_heaps_ = NULL; // tc&#38142;.
int ThreadCache::thread_heap_count_ = 0; // &#22810;&#23569;&#20010;tc
ThreadCache* ThreadCache::next_memory_steal_ = NULL; // &#19979;&#19968;&#27425;steal&#30340;tc.
bool ThreadCache::tsd_inited_ = false; // &#26159;&#21542;&#24050;&#32463;&#21021;&#22987;&#21270;&#20102;&#32447;&#31243;&#23616;&#37096;&#25968;&#25454;
pthread_key_t ThreadCache::heap_key_; // &#22914;&#26524;&#20351;&#29992;pthread&#32447;&#31243;&#23616;&#37096;&#25968;&#25454;&#35299;&#20915;&#21150;&#27861;

}
</pre>


</div>

</div>

<div id="outline-container-1-3-8-2" class="outline-5">
<h5 id="sec-1-3-8-2"><span class="section-number-5">1.3.8.2</span> InitModule</h5>
<div class="outline-text-5" id="text-1-3-8-2">




<pre class="src src-C++">void ThreadCache::InitModule() {
  SpinLockHolder h(Static::pageheap_lock());  // &#20840;&#23616;&#33258;&#36873;&#38145;
  if (!phinited) {
    Static::InitStaticVars(); // &#21021;&#22987;&#21270;&#19968;&#20123;&#38745;&#24577;&#25968;&#25454;
    threadcache_allocator.Init(); // PageHeapAllocator&lt;ThreadCache&gt;,sample_alloc&#21021;&#22987;&#21270;
    phinited = 1;
  }
}
</pre>


</div>

</div>

<div id="outline-container-1-3-8-3" class="outline-5">
<h5 id="sec-1-3-8-3"><span class="section-number-5">1.3.8.3</span> InitTSD</h5>
<div class="outline-text-5" id="text-1-3-8-3">




<pre class="src src-C++">void ThreadCache::InitTSD() {
  ASSERT(!tsd_inited_); // &#36825;&#20010;&#21464;&#37327;&#26631;&#35760;&#26159;&#21542;&#24050;&#32463;&#21021;&#22987;&#21270;&#20102;&#32447;&#31243;&#23616;&#37096;&#21464;&#37327;&#65292;&#22914;&#26524;&#27809;&#26377;&#30340;&#35805;&#37027;&#20040;&#26159;&#27809;&#26377;&#20219;&#20309;tc&#30340;.
  perftools_pthread_key_create(&amp;heap_key_, DestroyThreadCache); // &#36825;&#20010;&#23601;&#26159;&#35774;&#32622;&#22909;&#32447;&#31243;&#23616;&#37096;&#21464;&#37327;
  // &#22240;&#20026;&#27599;&#19968;&#20010;&#32447;&#31243;&#37117;&#20250;&#26377;&#19968;&#20010;&#32447;&#31243;&#23616;&#37096;&#21464;&#37327;thread cache.
  tsd_inited_ = true;
}
</pre>

<p>
然后我们看看DestroyThreadCache.很容易想到其实这个方法就是销毁掉线程的tc
</p>


<pre class="src src-C++">void ThreadCache::DestroyThreadCache(void* ptr) {
  // Note that <span class="org-string">"ptr"</span> cannot be NULL since pthread promises not
  // to invoke the destructor on NULL values, but for safety,
  // we check anyway.
  if (ptr == NULL) return;
  DeleteCache(reinterpret_cast&lt;ThreadCache*&gt;(ptr));
}
</pre>

<p>
我们可能会很想看看这个调用InitTSD的时机是什么？这个是放在一个全局静态变量里面一起调用的。之前已经提到了TCMallocGuard
</p>
</div>

</div>

<div id="outline-container-1-3-8-4" class="outline-5">
<h5 id="sec-1-3-8-4"><span class="section-number-5">1.3.8.4</span> GetCache</h5>
<div class="outline-text-5" id="text-1-3-8-4">

<p>关于GetCache我们也可以一起看看GetThreadHeap,GetCacheIfPresent,CreateCacheIfNecessary
</p>


<pre class="src src-C++">inline ThreadCache* ThreadCache::GetCache() {
  ThreadCache* ptr = NULL;
  if (!tsd_inited_) {
    InitModule(); // &#21021;&#22987;&#21270;&#27169;&#22359;
  } else {
    ptr = GetThreadHeap(); // &#30452;&#25509;&#26597;&#30475;&#26159;&#21542;&#23384;&#22312;
  }
  if (ptr == NULL) ptr = CreateCacheIfNecessary(); // &#22914;&#26524;&#19981;&#23384;&#22312;&#30340;&#35805;&#37027;&#20040;&#23601;&#21019;&#24314;
  return ptr;
}
</pre>


<p>
GetThreadHeap非常简单直接从线程局部变量里面取出即可
</p>


<pre class="src src-C++">inline ThreadCache* ThreadCache::GetThreadHeap() {
  return reinterpret_cast&lt;ThreadCache *&gt;(
      perftools_pthread_getspecific(heap_key_));
}
inline ThreadCache* ThreadCache::GetCacheIfPresent() {
  if (!tsd_inited_) return NULL;
  return GetThreadHeap();
}
</pre>


</div>

</div>

<div id="outline-container-1-3-8-5" class="outline-5">
<h5 id="sec-1-3-8-5"><span class="section-number-5">1.3.8.5</span> CreateCacheIfNecessary</h5>
<div class="outline-text-5" id="text-1-3-8-5">

<p>然后看看CreateCacheIfNecessary这个实现,看看是如何创建tc的
</p>


<pre class="src src-C++">ThreadCache* ThreadCache::CreateCacheIfNecessary() {
  // Initialize per-thread data if necessary
  ThreadCache* heap = NULL;
  {
    SpinLockHolder h(Static::pageheap_lock());
    const pthread_t me = pthread_self();
    // &#26597;&#25214;&#37324;&#38754;&#26159;&#21542;&#24050;&#32463;&#23384;&#22312;,&#27599;&#20010;&#32447;&#31243;&#37117;&#21019;&#24314;&#19968;&#20010;ThreadCache.
    // &#24182;&#19988;&#36825;&#20010;&#26159;&#25353;&#29031;&#38142;&#32452;&#32455;&#36215;&#26469;&#30340;&#12290;
    for (ThreadCache* h = thread_heaps_; h != NULL; h = h-&gt;next_) {
      if (h-&gt;tid_ == me) {
        heap = h;
        break;
      }
    }
    if (heap == NULL) heap = NewHeap(me);
  }
  if (!heap-&gt;in_setspecific_ &amp;&amp; tsd_inited_) {
    heap-&gt;in_setspecific_ = true; // &#36991;&#20813;setspecific&#37324;&#38754;&#36824;&#35843;&#29992;
    perftools_pthread_setspecific(heap_key_, heap);
    heap-&gt;in_setspecific_ = false;
  }
  return heap;
}
</pre>


</div>

</div>

<div id="outline-container-1-3-8-6" class="outline-5">
<h5 id="sec-1-3-8-6"><span class="section-number-5">1.3.8.6</span> NewHeap</h5>
<div class="outline-text-5" id="text-1-3-8-6">

<p>NewHeap是产生一个新的tc调用Init.将这个tc插入到队列里面.注意这里NewHeap已经加了锁了。
</p>


<pre class="src src-C++">ThreadCache* ThreadCache::NewHeap(pthread_t tid) {
  // Create the heap and add it to the linked list
  ThreadCache *heap = threadcache_allocator.New();
  heap-&gt;Init(tid); // &#35843;&#29992;Init
  heap-&gt;next_ = thread_heaps_; // &#32452;&#32455;&#25104;&#20026;&#19968;&#20010;&#21452;&#21521;&#38142;&#34920;
  heap-&gt;prev_ = NULL;
  if (thread_heaps_ != NULL) {
    thread_heaps_-&gt;prev_ = heap;
  } else {
    // This is the only thread heap at the momment.
    ASSERT(next_memory_steal_ == NULL);
    next_memory_steal_ = heap; // &#22914;&#26524;&#36825;&#20010;&#26159;&#31532;&#19968;&#20010;&#20803;&#32032;&#30340;&#35805;&#65292;&#37027;&#20040;&#35774;&#32622;next_memory_steal.
  }
  thread_heaps_ = heap;
  thread_heap_count_++; // tc&#25968;&#37327;.
  return heap;
}
</pre>


</div>

</div>

<div id="outline-container-1-3-8-7" class="outline-5">
<h5 id="sec-1-3-8-7"><span class="section-number-5">1.3.8.7</span> BecomeIdle</h5>
<div class="outline-text-5" id="text-1-3-8-7">

<p>BecomeIdle触发条件现在还不是很清楚，但是作用是认为这个tc没有必要了可以删除。不过在大部分使用应该不会有这个调用吧。
</p>


<pre class="src src-C++">void ThreadCache::BecomeIdle() {
  if (!tsd_inited_) return;              // No caches yet
  ThreadCache* heap = GetThreadHeap();
  if (heap == NULL) return;             // No thread cache to remove
  if (heap-&gt;in_setspecific_) return;    // Do not disturb the active caller

  heap-&gt;in_setspecific_ = true; // &#38450;&#27490;&#36882;&#24402;&#35843;&#29992;
  perftools_pthread_setspecific(heap_key_, NULL);
  heap-&gt;in_setspecific_ = false;
  if (GetThreadHeap() == heap) { // &#24212;&#35813;&#26159;&#19981;&#20250;&#35843;&#29992;&#36825;&#20010;&#37096;&#20998;&#36923;&#36753;&#30340;.
    // Somehow heap got reinstated by a recursive call to malloc
    // from pthread_setspecific.  We give up in this case.
    return;
  }
  // &#28982;&#21518;&#23558;&#36825;&#20010;heap&#37322;&#25918;&#25481;
  // We can now get rid of the heap
  DeleteCache(heap);
}
</pre>


<p>
这里我想到一个问题，就是如果不断地启动线程然后关闭线程，如果tid是不允许复用的话那么会导致thread_cache不断地开辟。
如果使用gettid的话那么可能会有这个情况，而如果用pthread_self的话可能就不会有了(至少从程序上看可以复用)
</p>


<pre class="src src-C++">#include &lt;cstdio&gt;
#include &lt;pthread.h&gt;

char buf[1024*1024];
void* foo(void* arg){
  return NULL;
}
int main() {
  pthread_t tid;
  for(int i=0;i&lt;10;i++){
    pthread_create(&amp;tid,NULL,foo,NULL);
    pthread_join(tid,NULL);
    printf(<span class="org-string">"%zu\n"</span>,static_cast&lt;size_t&gt;(tid));
    pthread_create(&amp;tid,NULL,foo,NULL);
    pthread_join(tid,NULL);
    printf(<span class="org-string">"%zu\n"</span>,static_cast&lt;size_t&gt;(tid));
  }
  return 0;
}
</pre>

<p>
从程序运行结果来看的话都是一样的tid.
</p>
</div>

</div>

<div id="outline-container-1-3-8-8" class="outline-5">
<h5 id="sec-1-3-8-8"><span class="section-number-5">1.3.8.8</span> Init</h5>
<div class="outline-text-5" id="text-1-3-8-8">

<p>注意这里Init已经在外围的NewHeap加锁了。这个地方进行初始化。设置一下最大分配多少空间以及初始化每一个slab
</p>


<pre class="src src-C++">void ThreadCache::Init(pthread_t tid) {
  size_ = 0;

  max_size_ = 0;
  IncreaseCacheLimitLocked(); // &#36825;&#20010;&#22320;&#26041;&#22312;&#35745;&#31639;&#21040;&#24213;&#21487;&#20197;&#20998;&#37197;&#22810;&#23569;max size.
  if (max_size_ == 0) {
    // There isn't enough memory to go around.  Just give the minimum to
    // this thread.
    // static const size_t kMaxSize    = 256 * 1024;(256K)
    // static const size_t kMinThreadCacheSize = kMaxSize * 2;(512K)
    max_size_ = kMinThreadCacheSize; // 512K.

    // Take unclaimed_cache_space_ negative.
    unclaimed_cache_space_ -= kMinThreadCacheSize; // &#37027;&#20040;&#30456;&#24403;&#20110;tc&#25345;&#26377;&#31354;&#38386;&#31354;&#38388;&#20063;&#23545;&#24212;&#20943;&#23569;
    ASSERT(unclaimed_cache_space_ &lt; 0);
  }

  next_ = NULL;
  prev_ = NULL;
  tid_  = tid;
  in_setspecific_ = false;
  for (size_t cl = 0; cl &lt; kNumClasses; ++cl) {
    list_[cl].Init(); // &#21021;&#22987;&#21270;&#27599;&#20010;slab
  }

  uint32_t sampler_seed;
  memcpy(&amp;sampler_seed, &amp;tid, sizeof(sampler_seed));
  sampler_.Init(sampler_seed); // &#21021;&#22987;&#21270;sampler TODO.???
}
</pre>

<p>
这里我们有两个问题没有搞懂，一个是slab到底结构是怎么样的，一个就是IncreaseCacheLimitLocked里面是如何计算max_size_的。
</p>
</div>

</div>

<div id="outline-container-1-3-8-9" class="outline-5">
<h5 id="sec-1-3-8-9"><span class="section-number-5">1.3.8.9</span> ThreadCache::FreeList</h5>
<div class="outline-text-5" id="text-1-3-8-9">

<p>freelist就是对应的slab.本质上数据结构就是一个单向链表，毕竟这个分配对于顺序没有任何要求。
</p>


<pre class="src src-C++">class FreeList {
 private:
  void*    list_;       // Linked list of nodes

  // On 64-bit hardware, manipulating 16-bit values may be slightly slow.
  uint32_t length_;      // Current length. // &#24403;&#21069;&#38271;&#24230;&#22810;&#23569;
  uint32_t lowater_;     // Low water mark for list length. // &#38271;&#24230;&#26368;&#23569;&#26102;&#20505;&#36798;&#21040;&#20102;&#22810;&#23569;
  uint32_t max_length_;  // Dynamic max list length based on usage. // &#35748;&#20026;&#30340;&#26368;&#22823;&#38271;&#24230;&#22810;&#23569;
  // Tracks the number of times a deallocation has caused
  // length_ &gt; max_length_.  After the kMaxOverages'th time, max_length_
  // shrinks and length_overages_ is reset to zero.
  uint32_t length_overages_; // &#36229;&#36807;&#26368;&#22823;&#38271;&#24230;&#30340;&#27425;&#25968;
};
</pre>

<p>
所有的这些参数其实都是为了进行方便做一些策略。
</p>
</div>

</div>

<div id="outline-container-1-3-8-10" class="outline-5">
<h5 id="sec-1-3-8-10"><span class="section-number-5">1.3.8.10</span> IncreaseCacheLimitLocked</h5>
<div class="outline-text-5" id="text-1-3-8-10">

<p>之前说到这个函数是在计算这个tc里面最多可以分配多少内存，那么看看这个函数的实现.调用这个函数的时候必然都是已经加了自旋锁的。
</p>


<pre class="src src-C++">void ThreadCache::IncreaseCacheLimitLocked() {
  if (unclaimed_cache_space_ &gt; 0) { // &#22914;&#26524;tc&#37324;&#38754;&#36824;&#26377;&#31354;&#38386;&#30340;&#20869;&#23481;&#30340;&#35805;&#65292;&#37027;&#20040;&#33719;&#21462;64KB&#36807;&#26469;
    // static const size_t kStealAmount = 1 &lt;&lt; 16;(64KB)
    // Possibly make unclaimed_cache_space_ negative.
    unclaimed_cache_space_ -= kStealAmount;
    max_size_ += kStealAmount;
    return;
  }
  // &#22914;&#26524;&#21457;&#29616;&#20381;&#28982;&#19981;&#22815;&#30340;&#35805;&#65292;&#37027;&#20040;&#20250;&#20174;&#27599;&#19968;&#20010;&#20197;&#21518;&#30340;tc&#37324;&#38754;&#33719;&#21462;&#20599;&#21462;&#37096;&#20998;&#20986;&#26469;.
  // &#36825;&#20010;&#38142;&#26159;&#25353;&#29031;next_memory_steal_&#21462;&#20986;&#26469;&#30340;&#65292;&#22914;&#26524;==NULL&#37027;&#20040;&#20174;&#22836;&#24320;&#22987;&#12290;
  // &#20294;&#26159;&#24456;&#24555;&#20250;&#21457;&#29616;&#36825;&#20010;max_size&#20854;&#23454;&#24182;&#19981;&#26159;&#19968;&#25104;&#19981;&#21464;&#30340;.
  // Don't hold pageheap_lock too long.  Try to steal from 10 other
  // threads before giving up.  The i &lt; 10 condition also prevents an
  // infinite loop in case none of the existing thread heaps are
  // suitable places to steal from.
  for (int i = 0; i &lt; 10;
       ++i, next_memory_steal_ = next_memory_steal_-&gt;next_) {
    // Reached the end of the linked list.  Start at the beginning.
    if (next_memory_steal_ == NULL) {
      ASSERT(thread_heaps_ != NULL);
      next_memory_steal_ = thread_heaps_;
    }
    if (next_memory_steal_ == this ||
        next_memory_steal_-&gt;max_size_ &lt;= kMinThreadCacheSize) {
      continue;
    }
    next_memory_steal_-&gt;max_size_ -= kStealAmount;
    max_size_ += kStealAmount;

    next_memory_steal_ = next_memory_steal_-&gt;next_;
    return;
  }
}
</pre>

<p>
总之tc的max_size分配策略的话就是根据当前所有tc剩余的空间，如果没有空间的话那么尝试从其他的tc里面获取。应该是想限制一开始每个tc的最大大小。
但是需要注意的是，这个tc最大大小并不是一成不变的，可能会随着时间变化而增加。
</p>
</div>

</div>

<div id="outline-container-1-3-8-11" class="outline-5">
<h5 id="sec-1-3-8-11"><span class="section-number-5">1.3.8.11</span> DeleteCache</h5>
<div class="outline-text-5" id="text-1-3-8-11">

<p>DeleteCache作用就是删除一个tc.大致逻辑非常简单，首先将自己持有的内存归还给central cache,然后将自己从tc的链中删除即可。
</p>


<pre class="src src-C++">void ThreadCache::DeleteCache(ThreadCache* heap) {
  // Remove all memory from heap
  heap-&gt;Cleanup(); // &#31245;&#21518;&#25105;&#20204;&#26597;&#30475;Cleanup&#23454;&#29616;&#12290;

  // Remove from linked list
  SpinLockHolder h(Static::pageheap_lock());
  if (heap-&gt;next_ != NULL) heap-&gt;next_-&gt;prev_ = heap-&gt;prev_;
  if (heap-&gt;prev_ != NULL) heap-&gt;prev_-&gt;next_ = heap-&gt;next_;
  if (thread_heaps_ == heap) thread_heaps_ = heap-&gt;next_;
  thread_heap_count_--;

  if (next_memory_steal_ == heap) next_memory_steal_ = heap-&gt;next_;
  if (next_memory_steal_ == NULL) next_memory_steal_ = thread_heaps_;
  unclaimed_cache_space_ += heap-&gt;max_size_;

  threadcache_allocator.Delete(heap);
}
</pre>

<p>
将自己删除之后需要重新计算thread_heaps以及next_memory_steal这两个变量。
</p>
</div>

</div>

<div id="outline-container-1-3-8-12" class="outline-5">
<h5 id="sec-1-3-8-12"><span class="section-number-5">1.3.8.12</span> Cleanup</h5>
<div class="outline-text-5" id="text-1-3-8-12">

<p>Cleanup是在DeleteCache，会在BecomeIdle里面可以调用，也会在销毁线程局部变量里面调用。作用就是将自己持有的内存归还给系统
</p>


<pre class="src src-C++">void ThreadCache::Cleanup() {
  // Put unused memory back into central cache
  for (int cl = 0; cl &lt; kNumClasses; ++cl) {
    if (list_[cl].length() &gt; 0) {
      ReleaseToCentralCache(&amp;list_[cl], cl, list_[cl].length());
    }
  }
}
</pre>

<p>
遍历所有的slab并且将上面挂在的free list归还给central cache.这个在ReleaseToCentralCache里面调用
</p>
</div>

</div>

<div id="outline-container-1-3-8-13" class="outline-5">
<h5 id="sec-1-3-8-13"><span class="section-number-5">1.3.8.13</span> ReleaseToCentralCache</h5>
<div class="outline-text-5" id="text-1-3-8-13">




<pre class="src src-C++">void ThreadCache::ReleaseToCentralCache(FreeList* src, size_t cl, int N) {
  ASSERT(src == &amp;list_[cl]);
  if (N &gt; src-&gt;length()) N = src-&gt;length(); // &#36825;&#20010;&#22320;&#26041;&#24863;&#35273;&#19981;&#26159;&#24456;&#26377;&#24517;&#35201;.&#19981;&#36807;&#20854;&#20182;&#22320;&#26041;&#30340;&#35805;&#21487;&#33021;&#36825;&#20004;&#20010;&#21442;&#25968;&#19981;&#21516;
  size_t delta_bytes = N * Static::sizemap()-&gt;ByteSizeForClass(cl); // &#20102;&#35299;&#26377;&#22810;&#23569;&#20010;&#23545;&#35937;&#21344;&#29992;&#20869;&#23384;&#22823;&#23567;&#37322;&#25918;.

  // We return prepackaged chains of the correct size to the central cache.
  // TODO: Use the same format internally in the thread caches?
  int batch_size = Static::sizemap()-&gt;num_objects_to_move(cl);
  while (N &gt; batch_size) { // &#27599;&#27425;&#24402;&#36824;batch_size&#20010;&#20869;&#23481;&#65292;&#36825;&#26679;central cache&#21487;&#20197;&#25918;&#22312;transfer cache&#37324;&#38754;
    void *tail, *head;
    src-&gt;PopRange(batch_size, &amp;head, &amp;tail);
    Static::central_cache()[cl].InsertRange(head, tail, batch_size);
    N -= batch_size;
  }
  void *tail, *head;
  src-&gt;PopRange(N, &amp;head, &amp;tail);
  Static::central_cache()[cl].InsertRange(head, tail, N);
  size_ -= delta_bytes;
}
</pre>

<p>
PopRange这个语义非常简单，但是我们稍微看看这个的实现，
</p>


<pre class="src src-C++">void PopRange(int N, void **start, void **end) {
  SLL_PopRange(&amp;list_, N, start, end);
  ASSERT(length_ &gt;= N);
  length_ -= N;
  if (length_ &lt; lowater_) lowater_ = length_;
}
</pre>

<p>
问题就在于，这里设置了lowater mark.如果当前的长度小于最低水位的话，那么需要更新最低水位。
</p>
</div>

</div>

<div id="outline-container-1-3-8-14" class="outline-5">
<h5 id="sec-1-3-8-14"><span class="section-number-5">1.3.8.14</span> Allocate</h5>
<div class="outline-text-5" id="text-1-3-8-14">

<p>Allocate就是从对应的slab里面分配出一个object.注意在Init时候的话每个tc里面是没有任何内容的，size_=0.FreeList也是空的。
</p>


<pre class="src src-C++">inline void* ThreadCache::Allocate(size_t size, size_t cl) {
  ASSERT(size &lt;= kMaxSize);
  ASSERT(size == Static::sizemap()-&gt;ByteSizeForClass(cl));

  FreeList* list = &amp;list_[cl];
  if (list-&gt;empty()) {
    return FetchFromCentralCache(cl, size); // &#22914;&#26524;list&#37324;&#38754;&#20026;&#31354;&#30340;&#35805;&#65292;&#37027;&#20040;&#23581;&#35797;&#20174;cc&#30340;cl&#37324;&#38754;&#20998;&#37197;size&#20986;&#26469;.
  }
  size_ -= size; // &#22914;&#26524;&#23384;&#22312;&#30340;&#35805;&#37027;&#20040;&#23601;&#30452;&#25509;-size&#24182;&#19988;&#24377;&#20986;&#19968;&#20010;&#20803;&#32032;
  return list-&gt;Pop();
}
</pre>


</div>

</div>

<div id="outline-container-1-3-8-15" class="outline-5">
<h5 id="sec-1-3-8-15"><span class="section-number-5">1.3.8.15</span> FetchFromCentralCache</h5>
<div class="outline-text-5" id="text-1-3-8-15">

<p>这个部分的逻辑是从cc里面取出一系列的slab对象出来。里面有很多策略，非常精巧
</p>


<pre class="src src-C++">void* ThreadCache::FetchFromCentralCache(size_t cl, size_t byte_size) {
  FreeList* list = &amp;list_[cl];
  ASSERT(list-&gt;empty());
  const int batch_size = Static::sizemap()-&gt;num_objects_to_move(cl);

  // &#30475;&#30475;&#27599;&#27425;&#20801;&#35768;&#30340;&#20998;&#37197;&#30340;&#20010;&#25968;&#26159;&#22810;&#23569;
  const int num_to_move = min&lt;int&gt;(list-&gt;max_length(), batch_size);
  void *start, *end;
  int fetch_count = Static::central_cache()[cl].RemoveRange(
      &amp;start, &amp;end, num_to_move);

  ASSERT((start == NULL) == (fetch_count == 0));
  // &#21462;&#20986;&#26469;&#24182;&#19988;&#35774;&#32622;&#19968;&#19979;&#24403;&#21069;&#32500;&#25252;&#30340;&#31354;&#38386;&#22823;&#23567;&#26159;&#22810;&#23569;
  if (--fetch_count &gt;= 0) {
    size_ += byte_size * fetch_count;
    list-&gt;PushRange(fetch_count, SLL_Next(start), end);
  }
  // &#36825;&#37324;&#38656;&#35201;&#22686;&#38271;max_length.&#22914;&#26524;&lt;batch_size&#30340;&#35805;&#37027;&#20040;+1
  // &#22914;&#26524;&gt;=batch_size&#30340;&#35805;&#65292;&#37027;&#20040;&#20250;&#35774;&#32622;&#25104;&#20026;&#26576;&#20010;&#19978;&#32447;
  // static const int kMaxDynamicFreeListLength = 8192;
  if (list-&gt;max_length() &lt; batch_size) {
    list-&gt;set_max_length(list-&gt;max_length() + 1);
  } else {
    int new_length = min&lt;int&gt;(list-&gt;max_length() + batch_size,
                              kMaxDynamicFreeListLength);
        // &#36825;&#37324;&#20063;&#38750;&#24120;&#22909;&#29702;&#35299;&#65292;&#25353;&#29031;batch_size&#26469;&#20998;&#37197;&#30340;&#35805;&#65292;&#21487;&#20197;&#30452;&#25509;&#20174;tc&#37324;&#38754;&#24471;&#21040;
    // &#20351;&#29992;&#36825;&#20010;&#20316;&#20026;max_kength&#30340;&#35805;&#36890;&#24120;&#24847;&#21619;&#30528;&#20998;&#37197;&#36895;&#24230;&#20250;&#26356;&#24555;.
    new_length -= new_length % batch_size;
    ASSERT(new_length % batch_size == 0);
    list-&gt;set_max_length(new_length);
  }
  return start;
}
</pre>


</div>

</div>

<div id="outline-container-1-3-8-16" class="outline-5">
<h5 id="sec-1-3-8-16"><span class="section-number-5">1.3.8.16</span> Deallocate</h5>
<div class="outline-text-5" id="text-1-3-8-16">

<p>释放内存部分非常简单，但是同样里面有很多策略。并且里面涉及到了tc的GC问题
</p>


<pre class="src src-C++">inline void ThreadCache::Deallocate(void* ptr, size_t cl) {
  FreeList* list = &amp;list_[cl];
  size_ += Static::sizemap()-&gt;ByteSizeForClass(cl); // &#37322;&#25918;&#20102;&#36825;&#20010;&#20869;&#23384;&#25152;&#20197;&#31354;&#38386;&#22823;&#23567;&#22686;&#22823;
  ssize_t size_headroom = max_size_ - size_ - 1;  // &#22312;size&#19978;&#38754;&#30340;&#35805;&#36824;&#26377;&#22810;&#23569;&#31354;&#38386;.

  list-&gt;Push(ptr); // &#24402;&#36824;
  ssize_t list_headroom =
      static_cast&lt;ssize_t&gt;(list-&gt;max_length()) - list-&gt;length(); // &#22312;&#38271;&#24230;&#19978;&#36824;&#26377;&#22810;&#23569;&#31354;&#38386;

  // There are two relatively uncommon things that require further work.
  // In the common case we're done, and in that case we need a single branch
  // because of the bitwise-or trick that follows.
  if ((list_headroom | size_headroom) &lt; 0) { // &#36825;&#20010;&#37096;&#20998;&#24212;&#35813;&#26159;&#26377;&#20219;&#24847;&#19968;&#20010;&lt;0&#30340;&#35805;&#65292;&#37027;&#20040;&#23601;&#24212;&#35813;&#36827;&#20837;&#12290;&#20248;&#21270;&#25163;&#27573;&#21543;.
    if (list_headroom &lt; 0) { // &#22914;&#26524;&#24403;&#21069;&#38271;&#24230;&gt;max_length&#30340;&#35805;&#65292;&#37027;&#20040;&#38656;&#35201;&#37325;&#26032;&#35774;&#32622;max_length.
      ListTooLong(list, cl);
    }
        // &#26465;&#20214;&#30456;&#24403; if(size_headroom &lt; 0)
        // &#22240;&#20026;ListTooLog&#20250;&#23581;&#35797;&#20462;&#25913;size_&#25152;&#20197;&#36825;&#37324;&#37325;&#26032;&#21028;&#26029;..:(tricky:(.
    if (size_ &gt;= max_size_) Scavenge(); // &#22914;&#26524;&#24403;&#21069;size&gt;max_size&#30340;&#35805;&#65292;&#37027;&#20040;&#38656;&#35201;&#36827;&#34892;GC.
  }
}
</pre>

<p>
然后我们这里看看这两个触发动作时如何执行的。
</p>
</div>

</div>

<div id="outline-container-1-3-8-17" class="outline-5">
<h5 id="sec-1-3-8-17"><span class="section-number-5">1.3.8.17</span> ListTooLong</h5>
<div class="outline-text-5" id="text-1-3-8-17">

<p>到这个地方必须思考一个问题，就是什么时候max_length会发生变化以及如何变化的(触发这些变化的意义是什么).
我们可以看到Allocate里面如果从cc里面取在不断地增加max_length(存在上限).问题是我们不能够让这个部分缓存太多的内容，
所以我们必须在一段时间内缩小max_length，一旦length&gt;max_length的话就会触发ListTooLong.
而ListTooLong里面的操作就是将max_length尝试缩小并且将一部分object归还给cc.
</p>


<pre class="src src-C++">void ThreadCache::ListTooLong(FreeList* list, size_t cl) {
  const int batch_size = Static::sizemap()-&gt;num_objects_to_move(cl);
  ReleaseToCentralCache(list, cl, batch_size); // &#39318;&#20808;&#23581;&#35797;&#23558;batch_size&#30340;&#20869;&#23481;&#24402;&#36824;&#21040;tc&#37324;&#38754;&#21462;

  // If the list is too long, we need to transfer some number of
  // objects to the central cache.  Ideally, we would transfer
  // num_objects_to_move, so the code below tries to make max_length
  // converge on num_objects_to_move.

  if (list-&gt;max_length() &lt; batch_size) {
    // Slow start the max_length so we don't overreserve.
    list-&gt;set_max_length(list-&gt;max_length() + 1);
  } else if (list-&gt;max_length() &gt; batch_size) {
    // If we consistently go over max_length, shrink max_length.  If we don't
    // shrink it, some amount of memory will always stay in this freelist.
    list-&gt;set_length_overages(list-&gt;length_overages() + 1); // &#35760;&#24405;&#19979;overage&#30340;&#27425;&#25968;
    if (list-&gt;length_overages() &gt; kMaxOverages) { // &gt; kMaxOverages&#30340;&#35805;&#37027;&#20040;&#38656;&#35201;&#23545;max_length&#36827;&#34892;&#32553;&#20943;.
      ASSERT(list-&gt;max_length() &gt; batch_size);
      list-&gt;set_max_length(list-&gt;max_length() - batch_size); // &#32553;&#20943;batch_size.
      list-&gt;set_length_overages(0);
    }
  }
}
</pre>

<p>
ListTooLong是第一个确保在tc里面不会持有太多内存的机制.虽然对这里的整个过程算是比较了解，但是没有从大体上想清楚这个是如何设计的:(
</p>
</div>

</div>

<div id="outline-container-1-3-8-18" class="outline-5">
<h5 id="sec-1-3-8-18"><span class="section-number-5">1.3.8.18</span> Scavenge</h5>
<div class="outline-text-5" id="text-1-3-8-18">

<p>同样Scavenge是第二个确保在tc里不会持有太多内存的机制。同样虽然对这个过程比较了解但是也没有从大体生了解这个策略是如何设计出来的。
</p>



<pre class="src src-C++">// Release idle memory to the central cache
void ThreadCache::Scavenge() {
  // If the low-water mark for the free list is L, it means we would
  // not have had to allocate anything from the central cache even if
  // we had reduced the free list size by L.  We aim to get closer to
  // that situation by dropping L/2 nodes from the free list.  This
  // may not release much memory, but if so we will call scavenge again
  // pretty soon and the low-water marks will be high on that call.
  //int64 start = CycleClock::Now();
  for (int cl = 0; cl &lt; kNumClasses; cl++) {
    FreeList* list = &amp;list_[cl];
    const int lowmark = list-&gt;lowwatermark(); // &#19978;&#19968;&#27425;&#26368;&#30701;&#30340;free list length&#26159;&#22810;&#23569;.&#22914;&#26524;free list length&#36234;&#38271;
        // &#24847;&#21619;&#30528;&#22312;&#22823;&#22810;&#25968;&#26102;&#20505;&#26377;&#24456;&#22810;&#31354;&#38386;&#20869;&#23384;&#26159;&#27809;&#26377;&#20351;&#29992;&#65292;&#25152;&#20197;&#21487;&#20197;&#23558;&#20854;&#24402;&#36824;.
    if (lowmark &gt; 0) {
      const int drop = (lowmark &gt; 1) ? lowmark/2 : 1; // &#23558;&#26368;&#26368;&#30701;&#30340;&#37096;&#20998;&#30340;1/2&#24402;&#36824;&#32473;cc.
      ReleaseToCentralCache(list, cl, drop);

      // Shrink the max length if it isn't used.  Only shrink down to
      // batch_size -- if the thread was active enough to get the max_length
      // above batch_size, it will likely be that active again.  If
      // max_length shinks below batch_size, the thread will have to
      // go through the slow-start behavior again.  The slow-start is useful
      // mainly for threads that stay relatively idle for their entire
      // lifetime.
      const int batch_size = Static::sizemap()-&gt;num_objects_to_move(cl);
      if (list-&gt;max_length() &gt; batch_size) { // &#35843;&#25972;max_length.
        list-&gt;set_max_length(
            max&lt;int&gt;(list-&gt;max_length() - batch_size, batch_size));
      }
    }
    list-&gt;clear_lowwatermark();
  }

  IncreaseCacheLimit(); // &#35302;&#21457;&#36825;&#20010;Scavenge&#26412;&#36523;&#30340;&#21407;&#22240;&#23601;&#26159;&#22240;&#20026;size_&gt;max_size_&#25152;&#20197;&#26377;&#24517;&#35201;&#25552;&#39640;max_size_.
}
</pre>


</div>
</div>
</div>

</div>

<div id="outline-container-1-4" class="outline-3">
<h3 id="sec-1-4"><span class="section-number-3">1.4</span> 用户对象</h3>
<div class="outline-text-3" id="text-1-4">

<p>tcmalloc.h
</p>

</div>

<div id="outline-container-1-4-1" class="outline-4">
<h4 id="sec-1-4-1"><span class="section-number-4">1.4.1</span> 函数入口</h4>
<div class="outline-text-4" id="text-1-4-1">

<p>我们还是以最初的函数入门进行分析，我们只是关注tc_malloc与tc_free.
</p>


<pre class="src src-C++">extern <span class="org-string">"C"</span> PERFTOOLS_DLL_DECL void* tc_malloc(size_t size) __THROW {
  void* result = do_malloc_or_cpp_alloc(size);
  MallocHook::InvokeNewHook(result, size);
  return result;
}

extern <span class="org-string">"C"</span> PERFTOOLS_DLL_DECL void tc_free(void* ptr) __THROW {
  MallocHook::InvokeDeleteHook(ptr);
  do_free(ptr);
}
</pre>

<p>
可以看到两个函数调用之前都有hook存在。hook是在malloc_hook_inl.h以及malloc_hook.cc里面定义的，通过一个HookList来进行管理。
调用Invoke时候就是遍历里面的内容，这个后续可以仔细分析。do_malloc_or_cpp_alloc里面可以看到，因为tc_new_mode==0所以实际调用的就是do_malloc这个函数。
我们首先关注malloc的过程，对于malloc过程了解清楚之后，那么free过程就非常直接了。
</p>
</div>

</div>

<div id="outline-container-1-4-2" class="outline-4">
<h4 id="sec-1-4-2"><span class="section-number-4">1.4.2</span> 分配逻辑</h4>
<div class="outline-text-4" id="text-1-4-2">

<p>我们先看看do_malloc这个过程
</p>


<pre class="src src-C++">inline void* do_malloc(size_t size) {
  void* ret = NULL;

  // The following call forces module initialization
  ThreadCache* heap = ThreadCache::GetCache(); // &#39318;&#20808;&#24471;&#21040;thread_cache
  if (size &lt;= kMaxSize) { // kMaxSize = 256K
    size_t cl = Static::sizemap()-&gt;SizeClass(size);
    size = Static::sizemap()-&gt;class_to_size(cl);
     // &#23581;&#35797;&#36827;&#34892;&#37319;&#26679;&#20998;&#37197;.
         // &#36825;&#37324;&#25105;&#20204;&#26242;&#26102;&#24573;&#30053;&#37319;&#26679;&#37096;&#20998;&#30340;&#36923;&#36753;
    if ((FLAGS_tcmalloc_sample_parameter &gt; 0) &amp;&amp; heap-&gt;SampleAllocation(size)) {
      ret = DoSampledAllocation(size);
    } else {
      // The common case, and also the simplest.  This just pops the
      // size-appropriate freelist, after replenishing it if it's empty.
      ret = CheckedMallocResult(heap-&gt;Allocate(size, cl)); // &#36825;&#20010;&#37096;&#20998;&#30340;&#23601;&#26159;&#30452;&#25509;&#22312;tc&#19978;&#38754;&#35843;&#29992;Allocate&#36827;&#34892;&#20998;&#37197;
    }
  } else {
    ret = do_malloc_pages(heap, size); // &#22914;&#26524;&#20998;&#37197;&#23545;&#35937;&#36807;&#22823;&#30340;&#35805;
  }
  if (ret == NULL) errno = ENOMEM;
  return ret;
}
</pre>


<p>
对于小对象分配逻辑已经清楚了，接着看看大对象分配调用do_malloc_pages这个部分
</p>


<pre class="src src-C++">inline void* do_malloc_pages(ThreadCache* heap, size_t size) {
  void* result;
  bool report_large;

  Length num_pages = tcmalloc::pages(size); // &#36716;&#25442;&#38656;&#35201;&#20998;&#37197;&#22810;&#23569;&#20010;pages.
  size = num_pages &lt;&lt; kPageShift;

  if ((FLAGS_tcmalloc_sample_parameter &gt; 0) &amp;&amp; heap-&gt;SampleAllocation(size)) { // &#21516;&#26679;&#25105;&#20204;&#26242;&#26102;&#24573;&#30053;&#37319;&#26679;&#37096;&#20998;
    result = DoSampledAllocation(size);

    SpinLockHolder h(Static::pageheap_lock());
    report_large = should_report_large(num_pages);
  } else {
    SpinLockHolder h(Static::pageheap_lock());
    Span* span = Static::pageheap()-&gt;New(num_pages);
    result = (span == NULL ? NULL : SpanToMallocResult(span)); // &#36825;&#20010;&#37096;&#20998;&#23601;&#26159;&#26816;&#26597;&#19968;&#19979;span&#26159;&#21542;OK,&#24050;&#32463;&#23558;span&#30340;slab(0)cache&#20303;.
    report_large = should_report_large(num_pages);  // &#21028;&#26029;&#36825;&#20010;pages&#26159;&#21542;&#24320;&#36767;&#36807;&#22823;
  }

  if (report_large) {
    ReportLargeAlloc(num_pages, result); // &#22914;&#26524;&#24320;&#36767;&#36807;&#22823;&#30340;&#35805;&#37027;&#20040;&#21487;&#20197;&#36873;&#25321;&#36827;&#34892;report.
  }
  return result;
}
</pre>


<p>
然后稍微看看should_report_large是如何判断的以及如何report
</p>


<pre class="src src-C++">// &#36890;&#36807;&#33719;&#21462;&#29615;&#22659;&#21464;&#37327;&#21363;&#21487;&#24471;&#21040;
const int64 kDefaultLargeAllocReportThreshold = static_cast&lt;int64&gt;(1) &lt;&lt; 30; // &#40664;&#35748;&#26159;1GB
DEFINE_int64(tcmalloc_large_alloc_report_threshold,
             EnvToInt64(<span class="org-string">"TCMALLOC_LARGE_ALLOC_REPORT_THRESHOLD"</span>,
                        kDefaultLargeAllocReportThreshold),
             <span class="org-string">"Allocations larger than this value cause a stack "</span>
             <span class="org-string">"trace to be dumped to stderr.  The threshold for "</span>
             <span class="org-string">"dumping stack traces is increased by a factor of 1.125 "</span>
             <span class="org-string">"every time we print a message so that the threshold "</span>
             <span class="org-string">"automatically goes up by a factor of ~1000 every 60 "</span>
             <span class="org-string">"messages.  This bounds the amount of extra logging "</span>
             <span class="org-string">"generated by this flag.  Default value of this flag "</span>
             <span class="org-string">"is very large and therefore you should see no extra "</span>
             <span class="org-string">"logging unless the flag is overridden.  Set to 0 to "</span>
             <span class="org-string">"disable reporting entirely."</span>);

// &#36825;&#20010;large_alloc_threshold&#32943;&#23450;&#35201;&#27604;kPageSize&#35201;&#25171;
static int64_t large_alloc_threshold =
  (kPageSize &gt; FLAGS_tcmalloc_large_alloc_report_threshold
   ? kPageSize : FLAGS_tcmalloc_large_alloc_report_threshold);

inline bool should_report_large(Length num_pages) {
  const int64 threshold = large_alloc_threshold;
  if (threshold &gt; 0 &amp;&amp; num_pages &gt;= (threshold &gt;&gt; kPageShift)) { // &#22914;&#26524;&#36229;&#36807;large_alloc_threshold&#30340;&#35805;
    // Increase the threshold by 1/8 every time we generate a report.
    // We cap the threshold at 8GiB to avoid overflow problems.
        // &#37027;&#20040;&#36825;&#27425;&#30340;threshold&#21487;&#33021;&#38656;&#35201;&#36827;&#34892;&#35843;&#25972;
    large_alloc_threshold = (threshold + threshold/8 &lt; 8ll&lt;&lt;30 // 8GB
                             ? threshold + threshold/8 : 8ll&lt;&lt;30);
    return true;
  }
  return false;
}
</pre>

<p>
然后看看如果进行report的.代码上看基本上就是打印出这个函数调用堆栈到stderr上面，使用的buffer空间1000B.
</p>


<pre class="src src-C++">static void ReportLargeAlloc(Length num_pages, void* result) {
  StackTrace stack;
  stack.depth = GetStackTrace(stack.stack, tcmalloc::kMaxStackDepth, 1);

  static const int N = 1000;
  char buffer[N];
  TCMalloc_Printer printer(buffer, N);
  printer.printf(<span class="org-string">"tcmalloc: large alloc %"</span>PRIu64<span class="org-string">" bytes == %p @ "</span>,
                 static_cast&lt;uint64&gt;(num_pages) &lt;&lt; kPageShift,
                 result);
  for (int i = 0; i &lt; stack.depth; i++) {
    printer.printf(<span class="org-string">" %p"</span>, stack.stack[i]);
  }
  printer.printf(<span class="org-string">"\n"</span>);
  write(STDERR_FILENO, buffer, strlen(buffer));
}
</pre>


</div>

</div>

<div id="outline-container-1-4-3" class="outline-4">
<h4 id="sec-1-4-3"><span class="section-number-4">1.4.3</span> 释放逻辑</h4>
<div class="outline-text-4" id="text-1-4-3">

<p>相对分配来说，释放逻辑要稍微简单一些.
</p>


<pre class="src src-C++">inline void do_free_with_callback(void* ptr, void (*invalid_free_fn)(void*)) {
  if (ptr == NULL) return;
  ASSERT(Static::pageheap() != NULL);  // Should not call free() before malloc()
  const PageID p = reinterpret_cast&lt;uintptr_t&gt;(ptr) &gt;&gt; kPageShift;
  Span* span = NULL;
  size_t cl = Static::pageheap()-&gt;GetSizeClassIfCached(p); // &#39318;&#20808;&#26597;&#30475;cache&#37324;&#38754;&#26159;&#21542;&#26377;class&#30340;&#20449;&#24687;

  if (cl == 0) { // &#22914;&#26524;&#27809;&#26377;class&#30340;&#20449;&#24687;&#30340;&#35805;&#65292;&#37027;&#20040;&#38656;&#35201;&#21435;pagemap&#37324;&#38754;&#26597;&#35810;&#21040;span.
    span = Static::pageheap()-&gt;GetDescriptor(p);
    if (!span) { // &#22914;&#26524;&#26597;&#35810;&#19981;&#21040;span&#30340;&#35805;&#37027;&#20040;&#35748;&#20026;&#36825;&#20010;&#25351;&#38024;&#24335;&#38169;&#35823;&#30340;
      // span can be NULL because the pointer passed in is invalid
      // (not something returned by malloc or friends), or because the
      // pointer was allocated with some other allocator besides
      // tcmalloc.  The latter can happen if tcmalloc is linked in via
      // a dynamic library, but is not listed last on the link line.
      // In that case, libraries after it on the link line will
      // allocate with libc malloc, but free with tcmalloc's free.
      (*invalid_free_fn)(ptr);  // Decide how to handle the bad free request
      return;
    }
        // &#28982;&#21518;&#21462;&#20986;slab class&#24182;&#19988;cache&#20303;.
    cl = span-&gt;sizeclass;
    Static::pageheap()-&gt;CacheSizeClass(p, cl);
  }
  if (cl != 0) { // &#22914;&#26524;&#26159;&#23567;&#23545;&#35937;&#37322;&#25918;&#30340;&#35805;
    ASSERT(!Static::pageheap()-&gt;GetDescriptor(p)-&gt;sample);
    ThreadCache* heap = GetCacheIfPresent(); // &#37027;&#20040;&#25105;&#24471;&#21040;&#24403;&#21069;&#32447;&#31243;&#30340;heap
    if (heap != NULL) {
      heap-&gt;Deallocate(ptr, cl); // &#28982;&#21518;&#20250;&#21463;&#21040;&#36825;&#20010;tc&#37324;&#38754;
    } else { // &#19981;&#30693;&#36947;&#36825;&#20010;&#24773;&#20917;&#20160;&#20040;&#26102;&#20505;&#20986;&#29616;&#65292;&#22914;&#26524;&#20986;&#29616;&#30340;&#35805;&#65292;&#37027;&#20040;&#23601;&#25918;&#21040;cc&#37324;&#38754;,&#38750;&#24120;&#30452;&#25509;.
      // Delete directly into central cache
      tcmalloc::SLL_SetNext(ptr, NULL);
      Static::central_cache()[cl].InsertRange(ptr, ptr, 1);
    }
  } else {
    SpinLockHolder h(Static::pageheap_lock());
    ASSERT(reinterpret_cast&lt;uintptr_t&gt;(ptr) % kPageSize == 0);
    ASSERT(span != NULL &amp;&amp; span-&gt;start == p);
    if (span-&gt;sample) { // &#26242;&#26102;&#19981;&#29702;&#20250;&#36825;&#20010;sample&#36923;&#36753;
      StackTrace* st = reinterpret_cast&lt;StackTrace*&gt;(span-&gt;objects);
      tcmalloc::DLL_Remove(span);
      Static::stacktrace_allocator()-&gt;Delete(st);
      span-&gt;objects = NULL;
    }
        // &#22914;&#26524;&#26159;&#22823;&#23545;&#35937;&#30340;&#35805;&#37027;&#20040;&#30452;&#25509;&#30001;pageheap&#37322;&#25918;.
    Static::pageheap()-&gt;Delete(span);
  }
}

// The default <span class="org-string">"do_free"</span> that uses the default callback.
inline void do_free(void* ptr) {
  return do_free_with_callback(ptr, &amp;InvalidFree); // &#40664;&#35748;&#24773;&#20917;&#23601;&#26159;&#25171;&#21360;&#19968;&#20010;log&#24182;&#19988;&#30452;&#25509;crash&#25481;.
}
</pre>


</div>
</div>

</div>

<div id="outline-container-1-5" class="outline-3">
<h3 id="sec-1-5"><span class="section-number-3">1.5</span> 扩展组件</h3>
<div class="outline-text-3" id="text-1-5">


</div>

<div id="outline-container-1-5-1" class="outline-4">
<h4 id="sec-1-5-1"><span class="section-number-4">1.5.1</span> Sampler</h4>
<div class="outline-text-4" id="text-1-5-1">

<p>TODO:
</p>
</div>

</div>

<div id="outline-container-1-5-2" class="outline-4">
<h4 id="sec-1-5-2"><span class="section-number-4">1.5.2</span> MallocExtension</h4>
<div class="outline-text-4" id="text-1-5-2">

<p>TODO:
</p>
</div>

</div>

<div id="outline-container-1-5-3" class="outline-4">
<h4 id="sec-1-5-3"><span class="section-number-4">1.5.3</span> MallocHook</h4>
<div class="outline-text-4" id="text-1-5-3">

<p>TODO:
</p>
</div>

</div>

<div id="outline-container-1-5-4" class="outline-4">
<h4 id="sec-1-5-4"><span class="section-number-4">1.5.4</span> HeapChecker</h4>
<div class="outline-text-4" id="text-1-5-4">

<p>TODO:
</p>
</div>

</div>

<div id="outline-container-1-5-5" class="outline-4">
<h4 id="sec-1-5-5"><span class="section-number-4">1.5.5</span> HeapProfiler</h4>
<div class="outline-text-4" id="text-1-5-5">

<p>TODO:
</p>
</div>

</div>

<div id="outline-container-1-5-6" class="outline-4">
<h4 id="sec-1-5-6"><span class="section-number-4">1.5.6</span> CPUProfiler</h4>
<div class="outline-text-4" id="text-1-5-6">

<p>TODO:
</p>
</div>
</div>

</div>

<div id="outline-container-1-6" class="outline-3">
<h3 id="sec-1-6"><span class="section-number-3">1.6</span> Discussion</h3>
<div class="outline-text-3" id="text-1-6">


</div>

<div id="outline-container-1-6-1" class="outline-4">
<h4 id="sec-1-6-1"><span class="section-number-4">1.6.1</span> tcmalloc中的 MmapSysAllocator::Alloc 疑问(nwlzee)</h4>
<div class="outline-text-4" id="text-1-6-1">

<p><b>Question</b> 
</p>



<pre class="example">您好，我看到这函数有点不了解。
在MmapSysAllocator::Alloc 中：

// 。。。
  if ((ptr &amp; (alignment - 1)) != 0) {
    adjust = alignment - (ptr &amp; (alignment - 1));
  }

  // Return the unused memory to the system
  if (adjust &gt; 0) {
    munmap(reinterpret_cast&lt;void*&gt;(ptr), adjust);
  }
  if (adjust &lt; extra) {
    munmap(reinterpret_cast&lt;void*&gt;(ptr + adjust + size), extra - adjust);
  }

  ptr += adjust;
  return reinterpret_cast&lt;void*&gt;(ptr);

我从man 手册知道munmap 是以page 单位大小释放的内存的，
当 munmap(reinterpret_cast&lt;void*&gt;(ptr), adjust); 释放adjust所
包含的页了，则返回 ptr += adjust (可能指向刚才释放的页中某一地址)，这地址ptr不是无效了？
</pre>



<hr/>

<p>
<b>Answer</b>
</p>
<p>
看看MmapSysAllocator::Alloc这个函数吧，假设这里的alignment==page_size的情况的话，
</p><ol>
<li>extra = alignment - pagesize; 所以extra==0
</li>
<li>ptr肯定和page_size对齐，因此adjust==0
</li>
</ol>

<p>所以你可以看到其实两个分支都没有走到的。
</p>
<p>
其实在实际使用的时候alignment通常也是page_size的倍数。如果alignment==k*page_size的话，你会发现
</p><ol>
<li>extra也是page_size倍数
</li>
<li>adjust也是page_size倍数
</li>
</ol>

<p>因此在munmap的时候不会存在跨越page_size边界这样的问题的。
</p>
<p>
最后你看看tcmalloc是怎么使用MmapSysAllocator对象的。相信你也看得非常仔细，tcmalloc是 DefaultSysAllocator创建两个对象
</p><ol>
<li>SbrkSysAllocator
</li>
<li>MmapSysAllocator
</li>
</ol>

<p>你看看DefaultSysAllocator调用情况，
</p>


<pre class="example">[blog@umeng-ubuntu-pc] &gt; grep "TCMalloc_SystemAlloc" *
common.cc:  void* result = TCMalloc_SystemAlloc(bytes, NULL);
page_heap.cc:#include "system-alloc.h"      // for TCMalloc_SystemAlloc, etc
page_heap.cc:  void* ptr = TCMalloc_SystemAlloc(ask &lt;&lt; kPageShift, &amp;actual_size, kPageSize);
page_heap.cc:      ptr = TCMalloc_SystemAlloc(ask &lt;&lt; kPageShift, &amp;actual_size, kPageSize);
system-alloc.cc:  // This doesn't overflow because TCMalloc_SystemAlloc has already
system-alloc.cc:    // NOTE: not a devmem_failure - we'd like TCMalloc_SystemAlloc to
system-alloc.cc:void* TCMalloc_SystemAlloc(size_t size, size_t *actual_size,
system-alloc.h:extern void* TCMalloc_SystemAlloc(size_t bytes, size_t *actual_bytes,
</pre>


<p>
你会看到实际上调用TCMalloc_SystemAlloc时候，alignment都是==kPageSize的。因此实际tcmalloc 使用时候不会出现这个问题。
</p></div>
</div>
</div>
</div>
</div>

<div id="postamble">
<p class="date">Date: 2014-01-02T19:55+0800</p>
<p class="creator"><a href="http://orgmode.org">Org</a> version 7.9.2 with <a href="http://www.gnu.org/software/emacs/">Emacs</a> version 23</p>
<a href="http://validator.w3.org/check?uri=referer">Validate XHTML 1.0</a>

</div>
<!-- Baidu Analytics BEGIN --><script type="text/javascript">var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F54a700ad7035f6e485eaf2300641e7e9' type='text/javascript'%3E%3C/script%3E"));</script><!-- Baidu Analytics END --><!-- Google Analytics BEGIN --><!-- <script type="text/javascript">  var _gaq = _gaq || [];  _gaq.push(['_setAccount', 'UA-31377772-1']);  _gaq.push(['_trackPageview']);  (function() {    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);  })();</script> --><!-- Google Analytics END --><!-- Baidu Button BEGIN --><!-- <script type="text/javascript" id="bdshare_js" data="type=tools&amp;uid=6762177" ></script><script type="text/javascript" id="bdshell_js"></script><script type="text/javascript"> document.getElementById("bdshell_js").src = "http://bdimg.share.baidu.com/static/js/shell_v2.js?cdnversion=" + Math.ceil(new Date()/3600000)</script> --><!-- Baidu Button END --><!-- G+ BEGIN --><!-- Place this render call where appropriate --><!-- <script type="text/javascript">  (function() {    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;    po.src = 'https://apis.google.com/js/plusone.js';    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);  })();</script> --><!-- G+ END --><!-- DISQUS BEGIN --><div id="disqus_thread"></div><script type="text/javascript">/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * *//* required: replace example with your forum shortname  */var disqus_shortname = 'feiskyblog';var disqus_identifier = 'tcmalloc.html';var disqus_title = 'tcmalloc.html';var disqus_url = 'http://blog.com/tcmalloc.html';/* * * DON'T EDIT BELOW THIS LINE * * */(function() {var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);})();</script><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a><!-- DISQUS END --></body>
</html>
