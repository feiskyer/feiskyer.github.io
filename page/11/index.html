<!doctype html><html lang=zh-cn><head><link href=https://gmpg.org/xfn/11 rel=profile><link rel=canonical href=https://feisky.xyz/><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=generator content="Hugo 0.148.0"><title>Feisky</title><meta name=twitter:card content="summary"><meta name=twitter:title content="Feisky"><meta name=twitter:site content="@feisky"><meta property="og:url" content="https://feisky.xyz/"><meta property="og:site_name" content="Feisky"><meta property="og:title" content="Feisky"><meta property="og:locale" content="zh_cn"><meta property="og:type" content="website"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/monokai.min.css><link rel=stylesheet href=/scss/triple-hyde.9e606bf339ab725ad1f7f06c9fe271099ac7709da56e4d541670f116255e9cd6.css integrity="sha256-nmBr8zmrclrR9/Bsn+JxCZrHcJ2lbk1UFnDxFiVenNY="><link rel=stylesheet href=/scss/print.2744dcbf8a0b2e74f8a50e4b34e5f441be7cf93cc7de27029121c6a09f9e77bc.css integrity="sha256-J0Tcv4oLLnT4pQ5LNOX0Qb58+TzH3icCkSHGoJ+ed7w=" media=print><link rel=stylesheet href=/scss/tocbot.5ef07cebc3c477b54270456f149ee02922479bb7555fd344b2c69f953b0e7e5e.css integrity="sha256-XvB868PEd7VCcEVvFJ7gKSJHm7dVX9NEssaflTsOfl4="><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js></script><script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=apple-touch-icon-precomposed sizes=144x144 href=/apple-touch-icon-144-precomposed.png><link rel="shortcut icon" href=/favicon.png><link rel=alternate type=application/rss+xml href=https://feisky.xyz/index.xml title=Feisky></head><body class=theme-base-0d><div class=sidebar><div class=container><div class=sidebar-about><span class=site__title><a href=https://feisky.xyz/>Feisky</a></span><div class=author-image><img src="https://www.gravatar.com/avatar/f86d2faa0f91793a2163d226d82a7620?s=240&d=mp" class="img--circle img--headshot element--center" alt=gravatar></div><p class=site__description></p></div><div class=collapsible-menu><input type=checkbox id=menuToggle>
<label for=menuToggle>Feisky</label><div class=menu-content><div><ul class=sidebar-nav><li><a href=https://time.geekbang.org/column/intro/100020901><span>Linux性能优化实战</span></a></li><li><a href=https://time.geekbang.org/column/intro/100104501><span>EBPF核心技术与实战</span></a></li><li><a href=https://kubernetes.feisky.xyz><span>Kubernetes指南</span></a></li><li><a href=https://sdn.feisky.xyz><span>SDN网络指南</span></a></li><li><a href=/assets/mp.png><span>微信公众号</span></a></li><li><a href=/about/><span>关于我</span></a></li></ul></div><section class=social><a href=https://twitter.com/feisky rel=me><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
</span></a><a href=https://github.com/feiskyer rel=me><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a></section></div></div><div class=copyright>&copy; 2025 feiskyer
<a href=https://creativecommons.org/licenses/by-sa/4.0>CC BY-SA 4.0</a></div><div class=builtwith>Built with <a href=https://gohugo.io>Hugo</a> ❤️ <a href=https://github.com/derme302/triple-hyde>triple-hyde</a>.</div></div></div><div class="content container"><div class=post-list><div class=post-list__item><span class=item__title--big><a href=/posts/2015-01-28-awk-examples/>awk examples</a>
</span><span class=item__date>Jan 01, 0001
</span><span><ul><li>precede each line by line number</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>awk <span style=color:#e6db74>&#39;{print NR, $0}&#39;</span> filename
</span></span></code></pre></div><ul><li>replace first field by line number</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>awk <span style=color:#e6db74>&#39;{$1=NR; print}&#39;</span> filename
</span></span></code></pre></div><ul><li>print field 1 and field 2</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>awk <span style=color:#e6db74>&#39;{print $1,$2}&#39;</span> fielname
</span></span></code></pre></div><ul><li>print last field</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>awk <span style=color:#e6db74>&#39;{print $NF}&#39;</span> filename
</span></span></code></pre></div><ul><li>print non empty lines</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>awk <span style=color:#e6db74>&#39;NF&gt;0{print $0}&#39;</span> filename
</span></span></code></pre></div><ul><li>print if more than 4 fields</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>awk <span style=color:#e6db74>&#39;NF&gt;4{print $0}&#39;</span> filename
</span></span></code></pre></div><ul><li>print matching lines (egrep)</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>awk <span style=color:#e6db74>&#39;/test.*/{print $0}&#39;</span>  filename
</span></span></code></pre></div><ul><li>print lines where first field matches</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>awk <span style=color:#e6db74>&#39;$1 ~ /^print.*/{print $0}&#39;</span> filename
</span></span></code></pre></div><ul><li>calcuting sum of field 2</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>awk <span style=color:#e6db74>&#39;BEGIN{sum=0}{sum+=$2}END{print sum}&#39;</span> filename
</span></span></code></pre></div><ul><li>for loop</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>awk <span style=color:#e6db74>&#39;{sum=0; for(i=1;i&lt;=NF;i++)sum+=$i; print sum}&#39;</span> filename
</span></span></code></pre></div><ul><li>make arrays</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>awk <span style=color:#e6db74>&#39;{n = split($0, array); print array[1], array[3]} &#39;</span> filename 
</span></span></code></pre></div><ul><li>reverse a file</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>awk <span style=color:#e6db74>&#39;{x[NR]=$0} END{for(i=NR;i&gt;0;i--)print x[i]}&#39;</span> filename 
</span></span></code></pre></div><ul><li>Associative Arrays</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>awk <span style=color:#e6db74>&#39;{amount[$1]=$2} END{for(name in amount) print name, amount[name]}&#39;</span> filename
</span></span></code></pre></div></span></div><div class=post-list__item><span class=item__title--big><a href=/posts/2015-01-27-bigdata/>bigdata</a>
</span><span class=item__date>Jan 01, 0001
</span><span><h1 id=awesome-big-data>Awesome Big Data</h1><p>A curated list of awesome big data frameworks, resources and other awesomeness. Inspired by <a href=https://github.com/ziadoz/awesome-php>awesome-php</a>, <a href=https://github.com/vinta/awesome-python>awesome-python</a>, <a href=https://github.com/Sdogruyol/awesome-ruby>awesome-ruby</a>, <a href=http://hadoopecosystemtable.github.io/>hadoopecosystemtable</a> & <a href=http://blog.andreamostosi.name/big-data/>big-data</a>.</p><p>Your contributions are always welcome!</p><ul><li><a href=#awesome-bigdata>Awesome Big Data</a><ul><li><a href=#frameworks>Frameworks</a></li><li><a href=#distributed-programming>Distributed Programming</a></li><li><a href=#distributed-filesystem>Distributed Filesystem</a></li><li><a href=#key-map-data-model>Key-Map Data Model</a></li><li><a href=#document-data-model>Document Data Model</a></li><li><a href=#key-value-data-model>Key-value Data Model</a></li><li><a href=#graph-data-model>Graph Data Model</a></li><li><a href=#newsql-databases>NewSQL Databases</a></li><li><a href=#columnar-databases>Columnar Databases</a></li><li><a href=#time-series-databases>Time-Series Databases</a></li><li><a href=#sql-like-processing>SQL-like processing</a></li><li><a href=#integrated-development-environments>Integrated Development Environments</a></li><li><a href=#data-ingestion>Data Ingestion</a></li><li><a href=#service-programming>Service Programming</a></li><li><a href=#scheduling>Scheduling</a></li><li><a href=#machine-learning>Machine Learning</a></li><li><a href=#benchmarking>Benchmarking</a></li><li><a href=#security>Security</a></li><li><a href=#system-deployment>System Deployment</a></li><li><a href=#applications>Applications</a></li><li><a href=#search-engine-and-framework>Search engine and framework</a></li><li><a href=#mysql-forks-and-evolutions>MySQL forks and evolutions</a></li><li><a href=#postgresql-forks-and-evolutions>PostgreSQL forks and evolutions</a></li><li><a href=#memcached-forks-and-evolutions>Memcached forks and evolutions</a></li><li><a href=#embedded-databases>Embedded Databases</a></li><li><a href=#business-intelligence>Business Intelligence</a></li><li><a href=#data-visualization>Data Visualization</a></li><li><a href=#internet-of-things-and-sensor-data>Internet of things and sensor data</a></li><li><a href=#interesting-readings>Interesting Readings</a></li><li><a href=#interesting-papers>Interesting Papers</a></li></ul></li><li><a href=#other-awesome-lists>Other Awesome Lists</a></li></ul><h2 id=frameworks>Frameworks</h2><ul><li><a href=http://hadoop.apache.org/>Apache Hadoop</a> - framework for distributed processing. Integrates MapReduce (parallel processing), YARN (job scheduling) and HDFS (distributed file system).</li></ul><h2 id=distributed-programming>Distributed Programming</h2><ul><li><a href=https://github.com/addthis/hydra>AddThis Hydra</a> - distributed data processing and storage system originally developed at AddThis.</li><li><a href=http://databricks.github.io/simr/>AMPLab SIMR</a> - run Spark on Hadoop MapReduce v1.</li><li><a href=http://crunch.apache.org/>Apache Crunch</a> - a simple Java API for tasks like joining and data aggregation that are tedious to implement on plain MapReduce.</li><li><a href=http://incubator.apache.org/projects/datafu.html>Apache DataFu</a> - collection of user-defined functions for Hadoop and Pig developed by LinkedIn.</li><li><a href=http://flink.incubator.apache.org/>Apache Flink</a> - high-performance runtime, and automatic program optimization.</li><li><a href=http://gora.apache.org/>Apache Gora</a> - framework for in-memory data model and persistence.</li><li><a href=http://hama.apache.org/>Apache Hama</a> - BSP (Bulk Synchronous Parallel) computing framework.</li><li><a href=http://wiki.apache.org/hadoop/MapReduce/>Apache MapReduce</a> - programming model for processing large data sets with a parallel, distributed algorithm on a cluster.</li><li><a href=https://pig.apache.org/>Apache Pig</a> - high level language to express data analysis programs for Hadoop.</li><li><a href=http://incubator.apache.org/s4/>Apache S4</a> - framework for stream processing, implementation of S4.</li><li><a href=http://spark.incubator.apache.org/>Apache Spark</a> - framework for in-memory cluster computing.</li><li><a href=http://spark.incubator.apache.org/docs/0.7.3/streaming-programming-guide.html>Apache Spark Streaming</a> - framework for stream processing, part of Spark.</li><li><a href=http://storm-project.net/>Apache Storm</a> - framework for stream processing by Twitter also on YARN.</li><li><a href=http://tez.incubator.apache.org/>Apache Tez</a> - application framework for executing a complex DAG (directed acyclic graph) of tasks, built on YARN.</li><li><a href=https://incubator.apache.org/projects/twill.html>Apache Twill</a> - abstraction over YARN that reduces the complexity of developing distributed applications.</li><li><a href=http://cascalog.org/>Cascalog</a> - data processing and querying library.</li><li><a href=http://vldbarc.org/pvldb/vldb2010/pvldb_vol3/I08.pdf>Cheetah</a> - High Performance, Custom Data Warehouse on Top of MapReduce.</li><li><a href=http://www.cascading.org/>Concurrent Cascading</a> - framework for data management/analytics on Hadoop.</li><li><a href=https://github.com/damballa/parkour>Damballa Parkour</a> - MapReduce library for Clojure.</li><li><a href=https://github.com/datasalt/pangool>Datasalt Pangool</a> - alternative MapReduce paradigm.</li><li><a href=https://www.datatorrent.com/>DataTorrent StrAM</a> - real-time engine is designed to enable distributed, asynchronous, real time in-memory big-data computations in as unblocked a way as possible, with minimal overhead and impact on performance.</li><li><a href=https://www.facebook.com/notes/facebook-engineering/under-the-hood-scheduling-mapreduce-jobs-more-efficiently-with-corona/10151142560538920>Facebook Corona</a> - Hadoop enhancement which removes single point of failure.</li><li><a href=http://peregrine_mapreduce.bitbucket.org/>Facebook Peregrine</a> - Map Reduce framework.</li><li><a href=https://www.facebook.com/notes/facebook-engineering/under-the-hood-data-diving-with-scuba/10150599692628920>Facebook Scuba</a> - distributed in-memory datastore.</li><li><a href=http://googledevelopers.blogspot.it/2014/06/cloud-platform-at-google-io-new-big.html>Google Dataflow</a> - create data pipelines to help themæingest, transform and analyze data.</li><li><a href=http://research.google.com/archive/mapreduce.html>Google MapReduce</a> - map reduce framework.</li><li><a href=http://research.google.com/pubs/pub41378.html>Google MillWheel</a> - fault tolerant stream processing framework.</li><li><a href=https://code.google.com/p/jaql/>JAQL</a> - declarative programming language for working with structured, semi-structured and unstructured data.</li><li><a href=http://kitesdk.org/docs/current/>Kite</a> - is a set of libraries, tools, examples, and documentation focused on making it easier to build systems on top of the Hadoop ecosystem.</li><li><a href=http://druid.io/>Metamarkers Druid</a> - framework for real-time analysis of large datasets.</li><li><a href=https://github.com/Netflix/PigPen>Netflix PigPen</a> - map-reduce for Clojure whiche compiles to Apache Pig.</li><li><a href=http://discoproject.org/>Nokia Disco</a> - MapReduce framework developed by Nokia.</li><li><a href=http://engineering.pinterest.com/post/91288882494/pinlater-an-asynchronous-job-execution-system>Pinterest Pinlater</a> - asynchronous job execution system.</li><li><a href=http://pydoop.sourceforge.net/docs/>Pydoop</a> - Python MapReduce and HDFS API for Hadoop.</li><li><a href=http://stratosphere.eu/>Stratosphere</a> - general purpose cluster computing framework.</li><li><a href=https://streamdrill.com/>Streamdrill</a> - usefull for counting activities of event streams over different time windows and finding the most active one.</li><li><a href=https://github.com/twitter/scalding>Twitter Scalding</a> - Scala library for Map Reduce jobs, built on Cascading.</li><li><a href=https://github.com/twitter/summingbird>Twitter Summingbird</a> - Streaming MapReduce with Scalding and Storm, by Twitter.</li><li><a href=https://blog.twitter.com/2014/tsar-a-timeseries-aggregator>Twitter TSAR</a> - TimeSeries AggregatoR by Twitter.</li></ul><h2 id=distributed-filesystem>Distributed Filesystem</h2><ul><li><a href=http://hadoop.apache.org/>Apache HDFS</a> - a way to store large files across multiple machines.</li><li><a href=http://www.fhgfs.com/cms/>BeeGFS</a> - formerly FhGFS, parallel distributed file system.</li><li><a href=http://ceph.com/ceph-storage/file-system/>Ceph Filesystem</a> - software storage platform designed.</li><li><a href=http://disco.readthedocs.org/en/latest/howto/ddfs.html>Disco DDFS</a> - distributed filesystem.</li><li><a href="https://www.facebook.com/note.php?note_id=76191543919">Facebook Haystack</a> - object storage system.</li><li><a href=https://google.com/>Google Colossus</a> - distributed filesystem (GFS2).</li><li><a href=https://google.com/>Google GFS</a> - distributed filesystem.</li><li><a href=http://research.google.com/pubs/pub36971.html>Google Megastore</a> - scalable, highly available storage.</li><li><a href=http://www.gridgain.org/>GridGain</a> - GGFS, Hadoop compliant in-memory file system.</li><li><a href=http://wiki.lustre.org/>Lustre file system</a> - high-performance distributed filesystem.</li><li><a href=https://www.quantcast.com/engineering/qfs/>Quantcast File System QFS</a> - open-source distributed file system.</li><li><a href=http://www.gluster.org/>Red Hat GlusterFS</a> - scale-out network-attached storage file system.</li><li><a href=http://tachyon-project.org/>Tachyon</a> - reliable file sharing at memory speed across cluster frameworks.</li></ul><h2 id=document-data-model>Document Data Model</h2><ul><li><a href=http://www.actian.com/products/operational-databases/>Actian Versant</a> - commercial object-oriented database management systems .</li><li><a href=https://crate.io/>Crate Data</a> - is an open source massively scalable data store. It requires zero administration.</li><li><a href=http://www.infoq.com/news/2014/06/facebook-apollo>Facebook Apollo</a> - Facebook’s Paxos-like NoSQL database.</li><li><a href=http://comsysto.github.io/jumbodb/>jumboDB</a> - document oriented datastore over Hadoop.</li><li><a href=http://data.linkedin.com/projects/espresso>LinkedIn Espresso</a> - horizontally scalable document-oriented NoSQL data store.</li><li><a href=http://www.marklogic.com/>MarkLogic</a> - Schema-agnostic Enterprise NoSQL database technology.</li><li><a href=http://www.mongodb.org/>MongoDB</a> - Document-oriented database system.</li><li><a href=http://www.ravendb.net/>RavenDB</a> - A transactional, open-source Document Database.</li><li><a href=http://www.rethinkdb.com/>RethinkDB</a> - document database that supports queries like table joins and group by.</li></ul><h2 id=key-map-data-model>Key Map Data Model</h2><p><strong>Note</strong>: There is some term confusion in the industry, and two different things are called &ldquo;Columnar Databases&rdquo;. Some, listed here, are distributed, persistent databases built around the &ldquo;key-map&rdquo; data model: all data has a (possibly composite) key, with which a map of key-value pairs is associated. In some systems, multiple such value maps can be associated with a key, and these maps are referred to as &ldquo;column families&rdquo; (with value map keys being referred to as &ldquo;columns&rdquo;).</p></span>... <a class=read-more-symbol href=/posts/2015-01-27-bigdata/>➦</a></div><div class=post-list__item><span class=item__title--big><a href=/posts/2015-02-10-cannot-change-locale/>cannot change locale</a>
</span><span class=item__date>Jan 01, 0001
</span><span><p>运行locale命令<span id=more-912></span><br>LANG=<br>LANGUAGE=<br>LC_CTYPE=&ldquo;POSIX&rdquo;<br>LC_NUMERIC=&ldquo;POSIX&rdquo;<br>LC_TIME=&ldquo;POSIX&rdquo;<br>LC_COLLATE=&ldquo;POSIX&rdquo;<br>LC_MONETARY=&ldquo;POSIX&rdquo;<br>LC_MESSAGES=&ldquo;POSIX&rdquo;<br>LC_PAPER=&ldquo;POSIX&rdquo;<br>LC_NAME=&ldquo;POSIX&rdquo;<br>LC_ADDRESS=&ldquo;POSIX&rdquo;<br>LC_TELEPHONE=&ldquo;POSIX&rdquo;<br>LC_MEASUREMENT=&ldquo;POSIX&rdquo;<br>LC_IDENTIFICATION=&ldquo;POSIX&rdquo;<br>LC_ALL=</p><p>修改profile</p><p>vi /etc/profile</p><p>添加如下内容</p><p>export LC_ALL=en_US.UTF-8</p><p>source /etc/profile</p><p>得到错误 setlocale: LC_ALL: cannot change locale (en_US.UTF-8): No such file or directory<br> 运行 dpkg-reconfigure locales</p><p>得到错误</p><p>perl: warning: Setting locale failed.<br>perl: warning: Please check that your locale settings:<br>        LANGUAGE = (unset),<br>        LC_ALL = &ldquo;en_US.UTF-8&rdquo;,<br>        LANG = &ldquo;en_US.UTF-8&rdquo;<br>    are supported and installed on your system.<br>perl: warning: Falling back to the standard locale (&ldquo;C&rdquo;).<br>locale: Cannot set LC_CTYPE to default locale: No such file or directory<br>locale: Cannot set LC_MESSAGES to default locale: No such file or directory<br>locale: Cannot set LC_ALL to default locale: No such file or directory<br>/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)</p></span>... <a class=read-more-symbol href=/posts/2015-02-10-cannot-change-locale/>➦</a></div><div class=post-list__item><span class=item__title--big><a href=/posts/2015-02-05-deploy-a-mesos-cluster-using-docker/>Deploy a Mesos Cluster Using Docker</a>
</span><span class=item__date>Jan 01, 0001
</span><span><p>his tutorial will show you how to bring up a single node <a href=http://mesosphere.com/>Mesos</a> cluster all provisioned out using <a href=http://docker.io/>Docker</a> containers (a future post will show how to easily scale this out to multi nodes or see the update on the bottom). This means that you can startup an entire cluster with 7 commands! Nothing to install except for starting out with a working Docker server.</p><p>This will startup 4 containers:</p><ol><li>ZooKeeper</li><li>Meso Master</li><li>Marathon</li><li>Mesos Slave Container</li></ol><p>As mentioned the only prerequisite is to have a working Docker server. This means you can bring up a local <a href=https://docs.vagrantup.com/v2/provisioning/docker.html>Vagrant box with Docker installed</a>, use <a href=http://boot2docker.io/>Boot2Docker</a>, use <a href=https://coreos.com/>CoreOS</a>, instance on AWS, or however you like to get a Docker server.</p></span>... <a class=read-more-symbol href=/posts/2015-02-05-deploy-a-mesos-cluster-using-docker/>➦</a></div><div class=post-list__item><span class=item__title--big><a href=/posts/2015-03-03-dive-in-linux-capabilites/>Dive in Linux capabilites</a>
</span><span class=item__date>Jan 01, 0001
</span><span><h3 id=introduction>Introduction</h3><p>Capabilities in Linux are flags that tell the kernel what the application is allowed to do, If you have no additional security mechanism in place, the Linux root user has all capabilities assigned to it. As capabilities are a way for running processes with some privileges, without having the need to grant them root privileges, it is important to understand that they exist.</p><p>Consider the ping utility. It is marked setuid root on some distributions, because the utility requires the (cap)ability to send raw packets. This capability is known as CAP_NET_RAW. However, thanks to capabilities, you can now mark the ping application with this capability and drop the setuid from the file. As a result, the application does not run with full root privileges anymore, but with the restricted privileges of the user plus one capability, namely the CAP_NET_RAW.</p></span>... <a class=read-more-symbol href=/posts/2015-03-03-dive-in-linux-capabilites/>➦</a></div><div class=post-list__item><span class=item__title--big><a href=/posts/2015-01-27-docker/>Docker</a>
</span><span class=item__date>Jan 01, 0001
</span><span><h3 id=简介>简介</h3><p>Docker 是 dotCloud 最近几个月刚宣布的开源引擎，旨在提供一种应用程序的自动化部署解决方案，简单的说就是，在 Linux 系统上迅速创建一个容器（类似虚拟机）并在容器上部署和运行应用程序，并通过配置文件可以轻松实现应用程序的自动化安装、部署和升级，非常方便。因为使用了容器，所以可以很方便的把生产环境和开发环境分开，互不影响，这是 docker 最普遍的一个玩法。更多的玩法还有大规模 web 应用、数据库部署、持续部署、集群、测试环境、面向服务的云计算、虚拟桌面 VDI 等等。</p></span>... <a class=read-more-symbol href=/posts/2015-01-27-docker/>➦</a></div><div class=post-list__item><span class=item__title--big><a href=/posts/2015-03-05-docker-acquires-sdn-startup-socketplane/>Docker acquires SDN startup SocketPlane</a>
</span><span class=item__date>Jan 01, 0001
</span><span><p>At <a href=http://socketplane.io/>Socketplane</a> we started out as four guys with a collectively strong belief in open source and open communities.  We aligned around a shared vision that we wanted to be a critical part of Docker’s once in a decade disruption. Now that we are <a href=http://www.businesswire.com/news/home/20150304005595/en/Docker-Acquires-SocketPlane-Drive-Open-Collaborative-Networking#.VPcQAVPF-Tk>part of the Docker team</a>, we couldn’t be happier.</p><p>We never looked to hedge our bets, our success was and obviously still is tied to the success of Docker. While there are many reasons that we decided to join the team, first and foremost Docker is unlike any other projects we have worked on in the past; the focus on user experience and simplicity is unmatched. Our early work with Docker during the open network design sprints gave us clear indications that the Docker maintainers were interested in being good open source stewards for the networking community in a project with an already staggering community of users and contributors. We also saw a genuine desire from Docker leadership to do right by both, individual contributors and the ecosystem. That made it all the more easy to jump in head first.</p></span>... <a class=read-more-symbol href=/posts/2015-03-05-docker-acquires-sdn-startup-socketplane/>➦</a></div><div class=post-list__item><span class=item__title--big><a href=/posts/2015-03-20-docker-in-tencent/>docker in tencent</a>
</span><span class=item__date>Jan 01, 0001
</span><span><p>腾讯内部对Docker有着广泛的使用，其基于Yarn的代号为Gaia的调度平台可以同时兼容Docker和非Docker类型的应用，并提供高并发任务调度和资源管理，它具有高度可伸缩性和可靠性，能够支持MR等离线业务。</p></span>... <a class=read-more-symbol href=/posts/2015-03-20-docker-in-tencent/>➦</a></div><div class=post-list__item><span class=item__title--big><a href=/posts/2015-01-27-docker-internal/>docker internal</a>
</span><span class=item__date>Jan 01, 0001
</span><span><p></style><title>docker-base</title></head><body><h2 id=abstract>Abstract</h2></p><p>本文在现有文档的基础上总结了以下几点内容</p><ol><li><p>docker的介绍，包括由来、适用场景等</p></li><li><p>docker背后的一系列技术 - namespace, cgroup, lxc, aufs等</p></li><li><p>docker在利用LXC的同时提供了哪些创新</p></span>... <a class=read-more-symbol href=/posts/2015-01-27-docker-internal/>➦</a></div><div class=post-list__item><span class=item__title--big><a href=/posts/2015-06-05-git-commit/>git commit修改前一次提交的方法</a>
</span><span class=item__date>Jan 01, 0001
</span><span><p>方法一：用–amend选项</p><pre tabindex=0><code>#修改需要修改的地方。
git add .
git commit –amend
</code></pre><p>注：这种方式可以比较方便的保持原有的Change-Id，推荐使用。</p><p>方法二：先reset，再修改</p><p>这是可以完全控制上一次提交内容的方法。但在与Gerrit配合使用时，需特别注意保持同一个commit的多次提交的Change-Id是不变的。为了保持提交到Gerrit的Change不变，需要复制对应的Change-Id到commit msg的最后，可以到Gerrit上对应的Change去复制.</p></span>... <a class=read-more-symbol href=/posts/2015-06-05-git-commit/>➦</a></div></div><ul class=pagination><li class=page-item><a href=/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/10/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/>1</a></li><li class=page-item><a class=page-link href=/page/2/>2</a></li><li class=page-item><a class=page-link href=/page/3/>3</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/10/>10</a></li><li class="page-item active"><a class=page-link href=/page/11/>11</a></li><li class=page-item><a class=page-link href=/page/12/>12</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/15/>15</a></li><li class=page-item><a href=/page/12/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/15/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-1GD5S2NKS3"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-1GD5S2NKS3")}</script></body></html>